# Include the application.conf file.
include required(classpath("application"))

system {
  max-concurrent-workflows = %(MAX_WORKFLOWS)d
  job-rate-control {
    jobs = 1
    per = 2 second
  }
  file-hash-cache = true
}

webservice {
  port = %(CROMWELL_PORT)d
  interface = 127.0.0.1
}

call-caching {
  enabled = %(CALL_CACHING)s
  invalidate-bad-cache-results = true
}

workflow-options {
  workflow-log-temporary = %(REMOVE_LOGS)s
}

aws {
  application-name = "cromwell"
  auths = [{
      name = "default"
      scheme = "default"
  }]
  # this should be replaced as necessary
  region = "us-west-2"
}

backend {
  default = "%(DEFAULT_BACKEND)s"
  providers {
    Local {
      actor-factory = "cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory"

      config {
        concurrent-job-limit = %(LOCAL_JOB_LIMIT)d
        filesystems {
          local {
            caching {
              duplication-strategy: [
                "soft-link"
              ]
            }
            localization: [
              "soft-link",
            ]
          }
        }
      }
    }
    SGE {
      actor-factory = "cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory"

      config {
        concurrent-job-limit = %(JMS_JOB_LIMIT)d
        exit-code-timeout-seconds = %(TIMEOUT)d

        script-epilogue = ""
        # Define runtime attributes for the SGE backend.
        # memory_gb is a special runtime attribute. See the cromwell README for more info.
        runtime-attributes = """
        Int cpu = 1
        Float? memory_gb
        String? queue_name
        String? project_name
        String? jms_args
        """

        # Script for submitting a job to SGE, using runtime attributess.
        # See the cromwell README for more info.
        submit = """
        qsub \
        -S /bin/bash \
	-V \
        -terse \
        -b n \
        -N ${job_name} \
        -wd ${cwd} \
        -o ${out} \
        -e ${err} \
        -pe smp ${cpu} \
        ${"-l h_vmem=" + memory_gb + "g"} \
        ${"-q " + queue_name} \
        ${"-P " + project_name} \
        ${jms_args} \
        ${script}
        """

        # command for killing/aborting
        kill = "qdel ${job_id}"

        # Command used at restart to check if a job is alive
        check-alive = "qstat -j ${job_id}"

        # How to search the submit output for a job_id
        job-id-regex = "(\\d+)"

        filesystems {
          local {
            localization: [
             "soft-link","hard-link","copy"
            ]
            caching {
              duplication-strategy: [
                "soft-link", "hard-link", "copy"
              ]
              caching-strategy: "file"
            }
          }
        }
      }
    }
    slurm {
      actor-factory = "cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory"
      config {
        concurrent-job-limit = %(JMS_JOB_LIMIT)d
        exit-code-timeout-seconds = %(TIMEOUT)d

        runtime-attributes = """
        Int cpu = 1
        Int? memory_gb
        String? queue_name
        String? jms_args
        """
 
        # If an 'exit-code-timeout-seconds' value is specified:
        # - When a job has not been alive for longer than this timeout
        # - And has still not produced an RC file
        # - Then it will be marked as Failed.
        # Warning: If set, Cromwell has to run 'check-alive' for every job at regular intervals (unrelated to this timeout)
 
        # exit-code-timeout-seconds = 120
 
        submit = """
            sbatch -J ${job_name} -D ${cwd} -o ${out} -e ${err} \
            ${"-p " + queue_name} \
            ${"-n " + cpu} \
            ${jms_args} \
            ${"--mem-per-cpu=" + memory_gb + "g"} \
            --wrap "/usr/bin/env bash ${script}"
        """
        kill = "scancel ${job_id}"
        check-alive = "squeue -j ${job_id}"
        job-id-regex = "Submitted batch job (\\d+).*"
 
        filesystems {
          local {
            localization: [
             "soft-link","hard-link","copy"
            ]
            caching {
              duplication-strategy: [
                "soft-link", "hard-link", "copy"
              ]
              caching-strategy: "file"
            }
          }
        }
      }
    }
    LSF {
      actor-factory = "cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory"
      config {
        submit = "bsub -J ${job_name} -cwd ${cwd} -o ${out} -e ${err} /usr/bin/env bash ${script}"
        kill = "bkill ${job_id}"
        check-alive = "bjobs ${job_id}"
        job-id-regex = "Job <(\\d+)>.*"
      }
    }
    TORQUE {
      actor-factory = "cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory"
      config {
        runtime-attributes = """
        String walltime = "1:00:00"
        Int cpu = 1
        Float memory_mb = 2048.0
        """

        submit = "qsub -N ${job_name} -lwalltime=${walltime},nodes=1:ppn=${cpu},mem=${ceil(memory_mb)}mb -d ${cwd} -o ${out} -e ${err} ${script}"
        kill = "qdel ${job_id}"
        check-alive = "qstat ${job_id}"
        job-id-regex = "(\\d+)"
      }
    }
#   AWSBATCH {
#     actor-factory = "cromwell.backend.impl.aws.AwsBatchBackendLifecycleActorFactory"
#     config {
#       numSubmitAttempts = 10
#       numCreateDefinitionAttempts = 10
#       # this should be replaced with the path to the Cromwell execution root
#       root = "REPLACE_ME"
#       auth = "default"
#       default-runtime-attributes {
#         # X = region, e.g. us-west-2
#         # Y = ???
#         # Z = ???
#         queueArn = "arn:aws:batch:X:Y:Z"
#       }
#       filesystems {
#         local {
#           auth = "default"
#           caching {
#            duplication-strategy =  "reference"
#           }
#         }
#       }
#     }
#   }
  }
}

%(DBPREFIX)sdatabase {
%(DBPREFIX)s  profile = "slick.jdbc.PostgresProfile$"
%(DBPREFIX)s  db {
%(DBPREFIX)s    driver = "org.postgresql.Driver"
%(DBPREFIX)s    url = "jdbc:postgresql://localhost:%(PGPORT)d/cromwell"
%(DBPREFIX)s    user = "%(DBUSER)s"
%(DBPREFIX)s    password = "%(DBPASSWORD)s"
%(DBPREFIX)s    port = %(PGPORT)d
%(DBPREFIX)s    connectionTimeout = 5000
%(DBPREFIX)s  }
%(DBPREFIX)s}
