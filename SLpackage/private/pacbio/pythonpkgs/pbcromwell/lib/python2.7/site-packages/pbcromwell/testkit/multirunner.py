"""
Parallel Cromwell test execution tool
"""

import multiprocessing
import functools
import argparse
import logging
import time
import os.path as op
import os
import sys

import pbcromwell.util
from pbcommand.cli import get_default_argparser_with_base_opts, pacbio_args_runner
from pbcommand.engine import run_cmd

from pbcromwell.testkit.workflow_runner import add_control_args
from pbcromwell.cli import setup_log, get_wdl_zip

__version__ = "0.1"
log = logging.getLogger(__name__)


def _get_runner_args(testkit_cfg, args):
    cmd_args = [
        op.abspath(testkit_cfg),
        "--max-time", str(args.max_time),
        "--host", args.host,
        "--port", str(args.port),
    ]
    if args.nproc is not None:
        cmd_args.extend(["--nproc", str(args.nproc)])
    for options_file in args.options:
        cmd_args.extend(["-o", op.abspath(options_file)])
    if args.target_size:
        cmd_args.extend(["--target-size", str(args.target_size)])
    if args.max_nchunks:
        cmd_args.extend(["--max-nchunks", str(args.max_nchunks)])
    if args.queue:
        cmd_args.extend(["--queue", args.queue])
    if args.cache is not None:
        if args.cache:
            cmd_args.append("--cache")
        else:
            cmd_args.append("--no-cache")
    if args.cli_only:
        cmd_args.append("--cli")
    if not args.abort_on_interrupt:
        cmd_args.append("--no-abort")
    if args.smrtlink:
        cmd_args.append("--smrtlink")
    elif args.smrtlink_cromwell:
        cmd_args.append("--smrtlink-cromwell")
    if args.user:
        cmd_args.extend(["--user", args.user])
    if args.password:
        cmd_args.extend(["--password", args.password])
    if args.pbvalidate:
        cmd_args.append("--pbvalidate")
    return cmd_args


def _run_job(testkit_cfg, base_dir, args):
    cfg_path = op.join(base_dir, testkit_cfg)
    os.chdir(op.dirname(cfg_path))
    cmd = ["pbcromwell-testkit-runner"] + _get_runner_args(cfg_path, args)
    with open("testkit.stdout", "w") as stdout:
        with open("testkit.stderr", "w") as stderr:
            result = run_cmd(" ".join(cmd), stdout, stderr)
    return testkit_cfg, result


def _log_result(base_dir, testkit_cfg, result):
    d = dict(r=result.exit_code,
             j=testkit_cfg,
             s=int(result.run_time),
             m=result.run_time / 60.0)
    test_dir = op.dirname(op.join(base_dir, testkit_cfg))
    msg = "exit code {r} in {s} sec ({m:.2f} min). job {j}".format(**d)
    if result.exit_code != 0:
        log.error(msg)
        stdout = op.join(test_dir, "testkit.stdout")
        stderr = op.join(test_dir, "testkit.stderr")
        with open(stderr) as stderr_in:
            log.error(stderr_in.read())
        log.error("See {o} for full test output".format(o=stdout))
    else:
        log.info(msg)


def _run_jobs(base_dir, testkit_cfgs, args):
    results = []
    started_at = time.time()
    # XXX to avoid connection errors when submitting a job to services,
    # the calls to pbtestkit-service-runner run staggered with a sleep
    # time of Constants.SLEEP_TIME between each job.  This allows us to
    # start many more near-simultaneous pbsmrtpipe jobs than would
    # otherwise be the case.
    SLEEP_TIME = 1
    nworkers = args.nworkers if args.nworkers > 0 else len(testkit_cfgs)
    log.info("Running {t} tests in {w} processes".format(
             t=len(testkit_cfgs), w=nworkers))
    pool = multiprocessing.Pool(nworkers)
    fxn = functools.partial(_log_result, base_dir)

    def callback(args): return fxn(*args)
    _results = []
    for i_cfg, testkit_cfg in enumerate(testkit_cfgs):
        log.debug("Running {c} with timeout of {t} seconds".format(
                  c=testkit_cfg, t=args.max_time))
        _results.append(pool.apply_async(_run_job,
                                         (testkit_cfg, base_dir, args),
                                         callback=callback))
        time.sleep(SLEEP_TIME)
    pool.close()
    pool.join()
    results.extend([r.get() for r in _results])
    pbcromwell.util.try_write_xray_json(args.xray_json_out,
            [(cfg, r.exit_code) for (cfg, r) in results],
            testExecutionKey=args.xray_tek)
    njobs = len(results)
    rcodes = [r.exit_code for _, r in results]
    nfailed = len([r for r in rcodes if r != 0])
    run_time = time.time() - started_at
    d = dict(n=njobs, x=nfailed, s=int(run_time), m=run_time / 60.0)
    msg = "Completed {n} jobs in {s} sec ({m:.2f} min) {x} failed.".format(**d)
    log.info(msg)
    return 0 if nfailed == 0 else max(rcodes)


def _run_args(args):
    _ = get_wdl_zip()  # make sure this works first
    fofn_file_name = op.abspath(args.test_suite)
    testkit_cfgs = list(pbcromwell.util.yield_from_fofn(fofn_file_name))
    base_dir = op.dirname(fofn_file_name)
    return _run_jobs(base_dir, testkit_cfgs, args)


def _get_parser():
    class Formatter(argparse.ArgumentDefaultsHelpFormatter,
                    argparse.RawDescriptionHelpFormatter):
        pass

    p = get_default_argparser_with_base_opts(
        description=__doc__,
        version=__version__)
    p.formatter_class = Formatter
    ARG = p.add_argument
    ARG("test_suite", help="FOFN of testkit configs")
    ARG("--nworkers", action="store", type=int, default=0,
        help="Number of jobs to run in parallel (or 0 to use as many as possible)")
    add_control_args(p)
    ARG("--pbvalidate", action="store_true",
        help="Run pbvalidate on all relevant output files")
    ARG("--xray-json-out", action="store", default="xray.json",
        help="X-ray JSON results file")
    ARG("--xray-tek", action="store", default=None,
        help="X-ray Test Execution Key to re-use (must already exist, if named)")
    return p


def main(argv=sys.argv):
    return pacbio_args_runner(
        argv=argv[1:],
        parser=_get_parser(),
        args_runner_func=_run_args,
        alog=log,
        setup_log_func=setup_log,
        dump_alarm_on_error=False)


if __name__ == "__main__":
    sys.exit(main(sys.argv))
