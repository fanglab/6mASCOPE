"""
Additional client utilities for SMRT Link testing.
"""

import logging
import json
import time
import os.path as op
import os
import sys

from pbcommand.models.common import TaskOptionTypes
from pbcommand.services._service_access_layer import get_smrtlink_client
from pbcommand.services.models import JobStates, ServiceEntryPoint
from pbcommand.utils import get_dataset_metadata

from pbcromwell.client import WorkflowError

log = logging.getLogger(__name__)


def _get_smrtlink_job_metadata(job):
    if not job.state in JobStates.ALL_COMPLETED:
        raise RuntimeError("Workflow has not completed yet, aborting")
    elif job.state != JobStates.SUCCESSFUL:
        raise WorkflowError("Workflow ended with state {s}".format(s=job.state))
    # FIXME this should use the datastore interface
    metadata_json = op.join(job.path, "workflow", "metadata-summary.json")
    return json.loads(open(metadata_json, "r").read())


def run_smrtlink_workflow(host,
                          port,
                          workflow_src,
                          inputs_d,
                          options_d,
                          dependencies_zip,
                          name="Cromwell job",
                          user=None,
                          password=None,
                          max_time=43200,
                          abort_on_interrupt=True):
    """
    Wrapper for running a Cromwell workflow through the SMRT Link REST API
    (which uses a POST request that is deliberately very similar, but not
    identical to Cromwell's).  Returns a minimal metadata object loaded from
    the job directory.
    """
    sal = get_smrtlink_client(host, port, user, password)
    log.info("starting cromwell analysis job...")
    job = sal.run_cromwell_workflow(name,
                                    workflow_src,
                                    json.dumps(inputs_d),
                                    json.dumps(options_d),
                                    dependencies_zip,
                                    time_out=max_time,
                                    abort_on_interrupt=abort_on_interrupt).job
    return _get_smrtlink_job_metadata(job)


def _get_smrtlink_entry_points(inputs_d):
    eps, new_inputs = {}, {}
    for k, v in inputs_d.iteritems():
        opt_id = k.split(".")[-1]
        if opt_id.startswith("eid_"):
            eps[opt_id] = v
        else:
            new_inputs[opt_id] = v
    return eps, new_inputs


def _get_smrtlink_workflow_options(inputs_d):
    wopts, new_inputs = [], {}
    for k, v in inputs_d.iteritems():
        option_id = k.split(".")[-1]
        if k in ["nproc", "log_level", "max_nchunks"]:
            pass  # TODO ???
        else:
            new_inputs[k] = v
    return wopts, new_inputs


def _get_smrtlink_task_options(inputs_d):
    topts = []
    for k, v in inputs_d.iteritems():
        d = {
            "optionId": k.split(".")[-1],
            "optionTypeId": TaskOptionTypes.from_any(v),
            "value": v
        }
        log.info("{optionId} ({optionTypeId}): {value}".format(**d))
        topts.append(d)
    return topts


def get_analysis_job_options(inputs_d):
    entry_points, inputs_d = _get_smrtlink_entry_points(inputs_d)
    workflow_options, inputs_d = _get_smrtlink_workflow_options(inputs_d)
    task_options = _get_smrtlink_task_options(inputs_d)
    return entry_points, task_options, workflow_options


# FIXME call caching is not working here
def run_smrtlink_analysis(host,
                          port,
                          name,
                          workflow_id,
                          inputs_d,
                          options_d,
                          user=None,
                          password=None,
                          max_time=43200,
                          abort_on_interrupt=True):
    """
    Wrapper for running a PbCromwell job in the SMRT Link REST API; this is
    a server interface for starting Cromwell workflows using a pbsmrtpipe-like
    job options model, for compatibility with the SMRT Link UI.
    """
    pipeline_id = "cromwell.workflows.{w}".format(w=workflow_id)
    entry_points, task_options, workflow_options = get_analysis_job_options(inputs_d)
    sal = get_smrtlink_client(host, port, user, password)
    service_entry_points = []
    for entry_id, dataset_xml in entry_points.iteritems():
        sal.run_import_local_dataset(dataset_xml, avoid_duplicate_import=True)
        md = get_dataset_metadata(dataset_xml)
        s = ServiceEntryPoint.from_d({
            "entryId": entry_id,
            "datasetId": md.uuid,
            "fileTypeId": md.metatype
        })
        log.info(s)
        service_entry_points.append(s)
    log.info("starting pbcromwell analysis job {i}...".format(i=pipeline_id))
    job = sal.run_by_pipeline_template_id(name,
                                          pipeline_id,
                                          service_entry_points,
                                          task_options=task_options,
                                          workflow_options=workflow_options,
                                          time_out=max_time,
                                          tags=("testkit", "pbcromwell"),
                                          abort_on_interrupt=abort_on_interrupt).job
    return _get_smrtlink_job_metadata(job)


def resume_smrtlink_job(host,
                        port,
                        job_id,
                        user=None,
                        password=None,
                        max_time=43200,
                        abort_on_interrupt=True):
    sal = get_smrtlink_client(host, port, user, password)
    job = sal.resume_job(job_id, max_time, abort_on_interrupt).job
    return _get_smrtlink_job_metadata(job)
