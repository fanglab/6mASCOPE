
from collections import defaultdict
from unittest import SkipTest
import operator as OP
import logging
import json
import os.path

from pbcommand.pb_io.report import load_report_from_json, dict_to_report

from pysiv2.custom.base import TestBase
from pysiv2.custom import utils as u

log = logging.getLogger(__name__)


def make_func(report_id, metric_id, ops_and_values):
    def test(self):
        if not self.HAVE_METRICS:
            self.fail("Missing report metrics")
        value = self._get_report_metric(report_id, metric_id)
        n_tested = 0
        for op, expected in ops_and_values:
            operator = getattr(OP, op)
            eqn = "%s .%s. %s" % (value, operator.__name__, expected)
            log.info("Comparing values of %s: %s" % (metric_id, eqn))
            self.assertTrue(operator(value, expected),
                            "%s: ! %s" % (metric_id, eqn))
            n_tested += 1
        if n_tested == 0:
            raise SkipTest("No values tested")
    return test

class TestReportMetrics(TestBase):

    class __metaclass__(type):

        def __new__(cls, classname, bases, classdict):
            json_file = "test_values2.json"
            if os.path.exists(json_file):
                f = open(json_file, 'r')
                test_values = u.unicode_to_string(json.load(f))
                metric_comparisons = defaultdict(list)
                classdict['report_ids'] = []
                for report_id, report_d in test_values["reports"].iteritems():
                    classdict['report_ids'].append(report_id)
                    id_short = report_id.split(".")[-1]
                    for k,v in report_d.iteritems():
                        fields = k.split("__")
                        metric_id = fields[0]
                        op = "eq"
                        if len(fields) == 2:
                            op = fields[1]
                        metric_comparisons[metric_id].append((op, v))
                    for metric_id, ops_and_values in metric_comparisons.iteritems():
                        test_name = "test_{r}_{m}".format(r=id_short,
                                                          m=metric_id)
                        test_f = make_func(report_id, metric_id, ops_and_values)
                        classdict[test_name] = test_f
            return type.__new__(cls, classname, bases, classdict)

    @classmethod
    def setUpClass(cls):
        super(TestReportMetrics, cls).setUpClass()
        cls.metric_dict = {}
        cls.HAVE_METRICS = False
        for rpt_id in cls.report_ids:
            report = cls.getReport(rpt_id)
            cls.metric_dict[rpt_id] = {a.id:a.value for a in report.attributes}
        cls.HAVE_METRICS = True

    @classmethod
    def getReport(cls, report_id):
        if cls.service_access_layer is None:
            report_json = cls.datastore.get_report(report_id)
            assert report_json is not None, "Can't find %s" % report_id
            return load_report_from_json(report_json)
        else:
            # load report from services, not raw file
            for rpt_info in cls.service_access_layer.get_analysis_job_reports(
                cls.job_id):
                file_info = rpt_info['dataStoreFile']
                source_id = file_info.file_id.split("-")[0]
                if source_id == report_id:
                    report_d = cls.service_access_layer.get_analysis_job_report_details(cls.job_id, file_info.uuid)
                    return dict_to_report(report_d)
            raise RuntimeError("Can't find {i} report".format(i=report_id))

    def _get_report_metric(self, report_id, metric_id):
        return self.metric_dict[report_id][metric_id]
