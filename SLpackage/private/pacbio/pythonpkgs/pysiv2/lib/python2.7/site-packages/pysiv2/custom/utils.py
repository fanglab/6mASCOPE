
from unittest import SkipTest
import tempfile
import logging
import sys
import math
import os

from pbcore.io import GffReader

from pbsmrtpipe.engine import backticks

log = logging.getLogger(__name__)


def check_gff_order(self, file_names, source_name):
    """
    Verify that records in a GFF file are sorted by genomic location.  Test for
    bug 27785.
    """
    n_files_checked = 0
    for file_name in file_names:
        log.info("Inspecting %s. . ." % file_name)
        sequences = set()
        with GffReader(file_name) as f:
            prev_start = prev_strand = prev_seq = None
            for rec in f:
                if source_name is not None and rec.source != source_name:
                    log.info(". . . wrong source, skipping")
                    break
                if rec.seqid != prev_seq:
                    self.assertFalse(rec.seqid in sequences,
                        ("The sequence %s appears in more than one "+
                         "contiguous block of records") % rec.seqid)
                    sequences.add(rec.seqid)
                    prev_start = prev_strand = None
                # XXX should we be using (rec.seqid, int(rec.start)) instead?
                start = int(rec.start)
                if prev_start is not None:
                    self.assertTrue(start >= prev_start, "%d < %d" % (start,
                        prev_start))
                    if start == prev_start:
                        self.assertNotEqual(rec.strand, prev_strand)
                prev_start = start
                prev_strand = rec.strand
                prev_seq = rec.seqid
            else:
                n_files_checked += 1
    if n_files_checked == 0:
        raise SkipTest("No GFF files with the appropriate records found")


def _align_to_reference(sequence, reference, job_dir):

    alignment_output = tempfile.NamedTemporaryFile(
        suffix="_consensus.out").name
    cmd = " ".join([
          "blasr", sequence, reference,
          "--minMatch", "15",
          "--maxMatch", "20",
          "--fastMaxInterval", "-m", "5",
          "--fastSDP", "--aggressiveIntervalCut",
          "--advanceExactMatches", "10",
          "--out", alignment_output])
    errCode, output, errorMessage, run_time = backticks(cmd)
    log.debug(cmd)

    if errCode is 0:
        log.info(output)
    elif errCode is 1:
        log.error(errorMessage)

    return alignment_output


def _get_snps(sequence, reference, job_dir):
    """
      Assumes reference is one contiguous sequence
      blasr '-m 5' header:
      qName qLength qStart qEnd qStrand tName tLength tStart tEnd tStrand score numMatch numMismatch numIns numDel mapQV qAlignedSeq matchPattern tAlignedSeq
    """

    if sequence is None:
        return None, -1
    alignment_output = _align_to_reference(sequence, reference, job_dir)

    with open(alignment_output, 'r') as f:
        alignment_output = f.readlines()

    total_match = 0

    reference_length = -1
    for line in alignment_output:
        x = line.split()
        reference_length = int(x[6])
        total_match = total_match + int(x[11])
    if reference_length < 0:
        log.error("Empty alignment output in %s" % alignment_output)

    snps = reference_length - total_match
    log.info('{x} SNPs detected'.format(x=snps))

    return snps, reference_length


def _get_qv(snpcount, length):
    """ Get accuracy based on snps comparison to reference

        Args:
             snpcount: Number of snps
             length: Number of nucleotides in fasta reference
        Returns:
             quality_value: A Phred Quality Score

    """

    if snpcount != 0:
        quality_value = round(
            -10 * math.log10(int(snpcount) / float(length)), 3)
    # if there are 0 snps, it means the query perfectly matches the reference
    else:
        quality_value = round(-10 * math.log10(1 / float(length)), 3)

    return quality_value


def calculate_qv(sequence, reference, job_dir):

    snps, reference_length = _get_snps(sequence, reference, job_dir)
    if snps is None and reference_length < 0:
        return None
    qv = _get_qv(snps, reference_length)
    log.info('QV: {q}'.format(q=qv))

    return qv


def unicode_to_string(json_object):
    """ Takes unicode formatted json_object and recursively converts
        to strings
    :param json_object: an object with unicode values created from json.load or json.loads
    :return: all unicodes converted to strings in json_object
    """
    if isinstance(json_object, dict):
        return {unicode_to_string(key): unicode_to_string(value) for key, value in json_object.iteritems()}
    elif isinstance(json_object, list):
        return [unicode_to_string(element) for element in json_object]
    elif isinstance(json_object, unicode):
        return json_object.encode('utf-8')
    else:
        return json_object


def main():
    """Main Point of entry"""
    job_dir = '/home/gconcepcion/p4/mainline/software/smrtanalysis/siv/testkit-jobs/sa3_pipelines/resequencing/saureus_2590946_0001_P6C4/tmp'
    old_fasta = '/home/gconcepcion/p4/mainline/software/smrtanalysis/siv/testkit-jobs/sa3_pipelines/resequencing/saureus_2590946_0001_P6C4/tmp/consensus.fasta'
    new_fasta = '/home/gconcepcion/p4/mainline/software/smrtanalysis/siv/testkit-jobs/sa3_pipelines/resequencing/saureus_2590946_0001_P6C4/tmp/file.contigset.dataset.fasta'
    ref = '/mnt/secondary-siv/references/S_aureus_USA300_TCH1516/sequence/S_aureus_USA300_TCH1516.fasta'
    job_dir = '/home/gconcepcion/p4/mainline/software/smrtanalysis/siv/testkit-jobs/sa3_pipelines/resequencing/tiny-lambda/job_output'


    old_qv = calculate_qv(old_fasta, ref, job_dir)
    new_qv = calculate_qv(new_fasta, ref, job_dir)
    print old_qv, new_qv

    return 0


if __name__ == '__main__':
    sys.exit(main())
