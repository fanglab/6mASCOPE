
"""
Scientific validity tests output of Long Amplicon Analysis (LAA) pipeline.
"""

import unittest
import logging
import json
import os.path as op
import tempfile
import re
import sys
import subprocess
import itertools
from collections import defaultdict, namedtuple

from numpy import log10

from pbcommand.models import FileTypes
from pbcore.io import FastqRecord, FastqReader, FastaReader, FastaWriter, FastaRecord
from pysiv2.custom.base import TestValuesLoader

# Default values for various options
PRIMER_TRIM             = 0
MIN_AMPLICON_COVERAGE   = 0.95
MAX_CONCATMER_AMPLICONS = 0
MAX_AMPLICON_COVERAGE   = 1.20
MAX_CONCATMER_AMPLICONS = 0
MAX_SPURIOUS_AMPLICONS  = 0
MAX_MISSING_AMPLICONS   = 0

_blasrM5 = namedtuple('blasrM5', ("qname qlength qstart qend qstrand "
                                 "tname tlength tstart tend tstrand "
                                 "score matches mismatches insertions deletions "
                                 "mapqv qstring astring tstring"))

log = logging.getLogger(__name__)

def find_hp(groups, pos):
    count = 0
    for g in groups:
        count += len(g)
        if count > pos:
            return g

def summarize_deletion( alignment, pos ):
    groups = [''.join(value) for key, value in itertools.groupby(alignment.tstring)]
    hp = find_hp(groups, pos)
    return "{0}{1}-D".format(len(hp), hp[0])

def summarize_insertion( alignment, pos ):
    groups = [''.join(value) for key, value in itertools.groupby(alignment.qstring)]
    hp = find_hp(groups, pos)
    return "{0}{1}-I".format(len(hp)-1, hp[0])

def summarize_indels( alignment ):
    indels = []
    insertions = [m.start() for m in re.finditer('-', alignment.tstring)]
    indels += [summarize_insertion(alignment, i) for i in insertions]
    deletions  = [m.start() for m in re.finditer('-', alignment.qstring)]
    indels += [summarize_deletion(alignment, i) for i in deletions]
    return ",".join(indels)

def read_sequences_by_barcode( sequence_file, trim ):
    paths = defaultdict(list)
    with FastqReader( sequence_file ) as handle:
        for record in handle:
            barcode  = record.name.split('_Cluster')[0][7:]
            if barcode == "65535--65535":
                continue
            if trim:
                trimSeq  = record.sequence[trim:-trim]
                trimQual = record.qualityString[trim:-trim]
                rec = FastqRecord( record.name, trimSeq, trimQual )
            else:
                rec = record
            paths[barcode].append( rec )
    return paths

def barcode_num( barcode ):
    if '-' in barcode:
        if barcode.startswith("F") or barcode.startswith("R"):
            # For F42--R42 style barcode names
            return int( barcode.split('-')[0][1:])
        elif barcode.startswith("lbc"):
            # For lbc1--lbc1 style barcode names
            return int( barcode.split('-')[0][3:])
        elif barcode.endswith("_Forward") or barcode.endswith("_Reverse"):
            # For 0001_Forward--0001_Reverse style barcode names
            return int( barcode[:4] )
        else:
            # For all other, hopefully barcode-index, barcode names
            return int( barcode.split('-')[0] )
    else:
        return int( barcode )

def num_reads( sequence_name ):
    id_root = sequence_name.split('/')[0]
    return int(id_root.split('NumReads')[1])

def write_temporary_fasta( record_list ):
    temp_fasta = tempfile.NamedTemporaryFile(suffix=".fasta", delete=False)
    with FastaWriter( temp_fasta.name ) as handle:
        for record in record_list:
            rec = FastaRecord( record.name, record.sequence )
            handle.writeRecord( rec )
    return temp_fasta

def align_sequences(query_seqs, reference_file, nproc=1):
    if not query_seqs:
        return []
    query_fasta = write_temporary_fasta( query_seqs )
    output_file = tempfile.NamedTemporaryFile(suffix=".m5", delete=False)
    args = [
        "blasr",
        "--noSplitSubreads",
        "--bestn", "1",
        "--nproc", str(nproc),
        "-m", "5",
        "--out", output_file.name,
        query_fasta.name,
        reference_file
    ]
    msg = "BLASR failed during call: '{0}'".format(' '.join(args))
    assert subprocess.call(args, stderr=subprocess.PIPE) == 0, msg
    assert op.isfile(output_file.name), msg
    recs = [_blasrM5._make(l.strip().split()) for l in open(output_file.name)]
    del query_fasta
    del output_file
    return recs

class TestBarcodedHLA(TestValuesLoader):
    """
    Test various metrics harvested from LAA output against expected values
    in ``test_values.json``.
    """

    FORCE_USE_LOCAL_DATASTORE = True

    @classmethod
    def setUpClass(cls):
        super(TestBarcodedHLA, cls).setUpClass()
        # Load sequence data from the datastore + reference test-values
        cls.test_values = cls.test_values["barcoded_hla"]
        cls.references  = cls.test_values["barcode_references"]
        cls.test_values = cls._set_default_values(cls.test_values)
        cls.off_targets = cls._read_off_targets()
        cls.amplicon_sequences = defaultdict(list)
        cls.chimeric_sequences = defaultdict(list)
        log.info("loading FASTQ files...")
        for file_id, file_info in cls.datastore.get_file_dict().iteritems():
            if op.basename(file_info.path) == "amplicon_analysis.fastq":
                log.info("reading amplicon sequences from {f}".format(
                         f=file_info.path))
                cls.amplicon_sequences.update(read_sequences_by_barcode(file_info.path, cls.test_values["primer_trim"]))
            if op.basename(file_info.path) == "amplicon_analysis_chimeras_noise.fastq":
                log.info("reading chimeric sequences from {f}".format(
                         f=file_info.path))
                cls.chimeric_sequences.update(read_sequences_by_barcode(file_info.path, cls.test_values["primer_trim"]))
        # Align each barcode's results to it's associated reference
        cls.alignments = cls._align_outputs()
        cls.totals     = cls._summarize_alignments()
        cls.stats      = cls._calculate_stats()

    @classmethod
    def _set_default_values(cls, test_values):
        test_values["primer_trim"] = int(test_values["primer_trim"]) \
                                            if "primer_trim" in test_values \
                                            else PRIMER_TRIM
        test_values["total_trim"] = 2 * test_values["primer_trim"]
        test_values["min_amplicon_coverage"] = float(test_values["min_amplicon_coverage"]) \
                                                        if "min_amplicon_coverage" in test_values \
                                                        else  MIN_AMPLICON_COVERAGE
        test_values["max_truncated_amplicons"] = int(test_values["max_truncated_amplicons"]) \
                                                        if "max_truncated_amplicons" in test_values \
                                                        else  MAX_CONCATMER_AMPLICONS
        test_values["max_amplicon_coverage"] = float(test_values["max_amplicon_coverage"]) \
                                                        if "max_amplicon_coverage" in test_values \
                                                        else  MAX_AMPLICON_COVERAGE
        test_values["max_concatmer_amplicons"] = int(test_values["max_concatmer_amplicons"]) \
                                                        if "max_concatmer_amplicons" in test_values \
                                                        else  MAX_CONCATMER_AMPLICONS
        test_values["max_spurious_amplicons"] = int(test_values["max_spurious_amplicons"]) \
                                                        if "max_spurious_amplicons" in test_values \
                                                        else  MAX_SPURIOUS_AMPLICONS
        test_values["max_missing_amplicons"] = int(test_values["max_missing_amplicons"]) \
                                                        if "max_missing_amplicons" in test_values \
                                                        else  MAX_MISSING_AMPLICONS
        return test_values

    @classmethod
    def _read_off_targets(cls):
        try:
            off_targets = set([l.strip() for l in open(cls.test_values["off_target_name_file"])])
        except:
            off_targets = set()
        return off_targets

    @classmethod
    def _align_outputs(cls):
        alignments = {}
        for barcode in sorted(cls.references, key=barcode_num):
            log.info("Aligning sequences from Barcode '{0}' to reference".format(barcode))
            query_seqs  = cls.amplicon_sequences[barcode]
            barcode_ref = cls.references[barcode]
            alignments[barcode] = align_sequences( query_seqs, barcode_ref )
        return alignments

    @classmethod
    def _summarize_alignments(cls):
        totals = {'perfect':[], 'missing':[], 'spurious':[], 'truncated':[], 'concatmer':[],
                'matches':0, 'mismatches':0, 'hasMismatch':[], 'indels':0, 'hasIndel':[]}
        for barcode in sorted(cls.references, key=barcode_num):
            totals = cls._summarize_alignments_by_barcode( barcode, totals )
        return totals

    @classmethod
    def _summarize_alignments_by_barcode(cls, barcode, totals):
        blasr_results = cls.alignments[barcode]
        barcode_ref   = cls.references[barcode]

        for expected in FastaReader(barcode_ref):
            results = [x for x in blasr_results if x.tname == expected.name.strip()]

            # End here if the sequence is missing or off-target
            if not results and expected.name not in cls.off_targets:
                totals['missing'].append( (expected.name, barcode) )
                continue
            if expected.name in cls.off_targets:
                continue

            # If we have one result take it, otherwise take the highest-coverage allele
            if len(results) == 1:
                aln = results[0]
            else:
                sorted_results = sorted(results, key=lambda r: num_reads(r.qname), reverse=True)
                aln = sorted_results[0]
                totals['spurious'] += sorted_results[1:]

            totals['matches'] += int(aln.matches)
            insertions = int(aln.insertions)
            deletions = int(aln.deletions)
            mismatches = int(aln.mismatches)
            coverage = (float(aln.qlength) + cls.test_values["total_trim"]) / float(aln.tlength)

            # Classify the sequence according to its imperfections
            if mismatches > 0:
                totals['mismatches'] += mismatches
                totals['hasMismatch'].append( aln )
                continue
            if insertions > 0 or deletions > 0:
                indels = insertions + deletions
                totals['indels'] += indels
                totals['hasIndel'].append( (aln, str(indels)) )
                continue
            if coverage < cls.test_values['min_amplicon_coverage']:
                totals['truncated'].append( (aln, str(coverage) ))
                continue
            if coverage > cls.test_values['max_amplicon_coverage']:
                totals['concatmer'].append( (aln, str(coverage) ))
                continue

            # If we made it this far, the alignment is perfect
            totals['perfect'].append( aln )
        return totals

    @classmethod
    def _calculate_stats(cls):
        stats = {}
        # Calculate over-all result QV
        stats['total_errors'] = cls.totals['mismatches'] + cls.totals['indels']
        if stats['total_errors'] == 0:
            stats['error_rate'] = 0
            stats['qv'] = 60
        else:
            stats['error_rate'] = stats['total_errors'] / float( cls.totals['matches'] )
            stats['qv'] = int(-10 * log10( stats['error_rate'] ))

        # Count the total number of sequences of various types
        stats['perfect']   = len(cls.totals['perfect'])
        stats['missing']   = len(cls.totals['missing'])
        stats['spurious']  = len(cls.totals['spurious'])
        stats['truncated'] = len(cls.totals['truncated'])
        stats['concatmer'] = len(cls.totals['concatmer'])
        stats['mismatch']  = len(cls.totals['hasMismatch'])
        stats['indel']     = len(cls.totals['hasIndel'])
        stats['good']      = stats['perfect'] + stats['truncated'] + stats['indel']
        stats['total']     = float(stats['good'] + stats['missing'] + stats['mismatch'])

        # Calculate various useful percentages
        stats['perfect_pct']   = 100 * round(stats['perfect']   / stats['total'],  3)
        stats['good_pct']      = 100 * round(stats['good']      / stats['total'],  3)
        stats['missing_pct']   = 100 * round(stats['missing']   / stats['total'],  3)
        stats['spurious_pct']  = 100 * round(stats['spurious']  /
                                            (stats['spurious']  + stats['total']), 3)
        stats['truncated_pct'] = 100 * round(stats['truncated'] / stats['total'],  3)
        stats['concatmer_pct'] = 100 * round(stats['concatmer'] / stats['total'],  3)
        stats['mismatch_pct']  = 100 * round(stats['mismatch']  / stats['total'],  3)
        stats['indel_pct']     = 100 * round(stats['indel']     / stats['total'],  3)
        return stats

    def test_perfect_amplicons(self):
        """
        Test that the number of perfect consensus sequences is at least the
        specified minimum value (``min_perfect_amplicons``).
        """
        msg = "Too few perfect consensus sequences ({0} to {1} ({2}%))".format(
                self.stats['perfect'], self.test_values['min_perfect_amplicons'], self.stats['perfect_pct'])
        self.assertGreaterEqual(self.stats['perfect'],
                                self.test_values['min_perfect_amplicons'],
                                msg)

    def test_good_amplicons(self):
        """
        Test that the number of good consensus sequences is at least the
        specified minimum value (``min_good_amplicons``).
        """
        msg = "Too few good consensus sequences ({0} to {1} ({2}%))".format(
                self.stats['good'], self.test_values['min_good_amplicons'], self.stats['good_pct'])
        self.assertGreaterEqual(self.stats['good'],
                                self.test_values['min_good_amplicons'],
                                msg)

    def test_missing_amplicons(self):
        """
        Test that the number of missing amplicon consensus sequences is no
        greater than the specified maximum value (``max_missing_amplicons``).
        """
        missing = ',\n'.join(["{0} from Barcode '{1}'".format(m[0], m[1]) for m in  self.totals['missing']])
        msg = "Too many missing consensus sequences ({0} to {1})\n[{2}]".format(
                self.stats['missing'], self.test_values['max_missing_amplicons'], missing)
        self.assertLessEqual(self.stats['missing'],
                             self.test_values['max_missing_amplicons'],
                             msg)

    def test_spurious_amplicons(self):
        """
        Test that the number of spurious consensus sequences is no greater than
        the specified maximum value (``max_spurious_amplicons``).
        """
        spurious = ',\n'.join(["{0} for {1}".format(a.qname, a.tname) for a in self.totals['spurious']])
        msg = "Too many spurious consensus sequences ({0} to {1})\n[{2}]".format(
                self.stats['spurious'], self.test_values['max_spurious_amplicons'], spurious)
        self.assertLessEqual(self.stats['spurious'],
                             self.test_values['max_spurious_amplicons'],
                             msg)

    def test_truncated_amplicons(self):
        """
        Test that the number of truncated consensus sequences is no greater
        than the specified maximum value (``max_truncated_amplicons``).
        """
        truncated = ',\n'.join(["{0} for {1}".format(a[1], a[0].qname) for a in self.totals['truncated']])
        msg = "Too many truncated consensus sequences ({0} to {1})\n[{2}]".format(
                self.stats['truncated'], self.test_values["max_truncated_amplicons"], truncated)
        self.assertLessEqual(self.stats['truncated'],
                             self.test_values["max_truncated_amplicons"],
                             msg)

    def test_concatmer_amplicons(self):
        """
        Test that the number of concatmers is no greater than the specified
        maximum value (``max_concatmer_amplicons``).
        """
        concatmer = ',\n'.join(["{0} for {1}".format(a[1], a[0].qname) for a in self.totals['concatmer']])
        msg = "Too many concatmer consensus sequences ({0} to {1})\n[{2}]".format(
                self.stats['concatmer'], self.test_values["max_concatmer_amplicons"], concatmer)
        self.assertLessEqual(self.stats['concatmer'],
                             self.test_values["max_concatmer_amplicons"],
                             msg)

    def test_amplicons_with_mismatch(self):
        """
        Test that the number of consensus sequences with mismatches is no
        greater than the specified maximum value (``max_amplicons_with_mismatches``).
        """
        mismatch = ',\n'.join(["{0} in {1} for {2}".format(a.mismatches, a.qname, a.tname) for a in self.totals['hasMismatch']])
        msg = "Too many consensus sequences with mismatch errors ({0} to {1})\n[{2}]".format(
                self.stats['mismatch'], self.test_values['max_amplicons_with_mismatches'], mismatch)
        self.assertLessEqual(self.stats['mismatch'],
                             self.test_values['max_amplicons_with_mismatches'],
                             msg)

    def test_num_mismatches(self):
        """
        Test that the number of mismatch errors is no greater than the
        specified maximum value (``max_mismatches``).
        """
        msg = "Too many mismatch errors in total ({0} to {1})".format(
                self.totals['mismatches'], self.test_values['max_mismatches'])
        self.assertLessEqual(self.totals['mismatches'],
                             self.test_values['max_mismatches'],
                             msg)

    def test_amplicons_with_indels(self):
        """
        Test that the number of consensus sequences with indel errors is no
        greater than the specified maximum value (``max_amplicons_with_indels``).
        """
        indel = ',\n'.join(["{0} in {1} for {2}".format(summarize_indels(a[0]), a[0].qname, a[0].tname) for a in self.totals['hasIndel']])
        msg = "Too many consensus sequences with indel errors ({0} to {1})\n[{2}]".format(
                self.stats['indel'], self.test_values['max_amplicons_with_indels'], indel)
        self.assertLessEqual(self.stats['indel'],
                             self.test_values['max_amplicons_with_indels'],
                             msg)

    def test_num_indels(self):
        """
        Test that the number of insertion and deletion errors is no greater
        than the specified maximum value (``max_indels``).
        """
        msg = "Too many insertion/deletion errors in total ({0} to {1})".format(
                self.totals['indels'], self.test_values['max_indels'])
        self.assertLessEqual(self.totals['indels'],
                             self.test_values['max_indels'],
                             msg)

    def test_average_sequence_quality(self):
        """
        Check that the average sequence quality is at least the specified
        minimum value (``min_qv``).
        """
        msg = "Over-all consensus sequence quality too low ({0} to {1})".format(
                self.stats['qv'], self.test_values['min_qv'])
        self.assertGreaterEqual(self.stats['qv'],
                                self.test_values['min_qv'],
                                msg)
