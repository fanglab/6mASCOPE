
"""
Generate a report on SubreadSet barcoding.
"""

from __future__ import division
from collections import defaultdict, namedtuple
from pprint import pformat
import functools
import itertools
import warnings
import logging
import os.path as op
import os
import sys

import numpy as np

from pbcommand.cli import pbparser_runner
from pbcommand.models.report import Report, Table, Column, Attribute, Plot, PlotGroup
from pbcommand.models import DataStore, FileTypes, SymbolTypes, get_pbparser, DataStoreFile
from pbcommand.utils import setup_log, get_dataset_metadata, pool_map
from pbcore.io import openDataSet, BarcodeSet, SubreadSet, ConsensusReadSet, DataSetMetaTypes

from pbreports.plot.helper import make_histogram, make_2d_histogram, get_blue, get_fig_axes_lpr, save_figure_with_thumbnail, DEFAULT_DPI, DEFAULT_THUMB_DPI
from pbreports.plot.plotly_helper import to_plotly_plot, to_simple_layout, to_sample_heatmap
from pbreports.io.specs import load_spec
from pbreports.io.barcode import (get_biosample_dict, BarcodeGroup,
                                  get_reads_by_barcode,
                                  get_unbarcoded_reads_info,
                                  Constants as BaseConstants)
from pbreports.report import subread_stats, ccs2
from pbreports.statistics import mean_int

log = logging.getLogger(__name__)
__version__ = '6.3'

spec = load_spec("barcode")


class Constants(BaseConstants):
    MAX_SUB_REPORTS = 768
    MAX_NPROC = SymbolTypes.MAX_NPROC
    MIN_BQ_FILTER = 26 # see also pbcoretools.file_utils
    VERSION = __version__
    DOC = __doc__

    TOOL_ID = "pbreports.tasks.barcode_report"
    TOOL_NAME = "barcode_report"
    DRIVER_EXE = "python -m pbreports.report.barcode --resolved-tool-contract"
    FILE_TYPE_READS_IN = FileTypes.DS_SUBREADS

    A_NBARCODES = "n_barcodes"
    A_MEAN_READS = "mean_reads"
    A_MAX_READS = "max_reads"
    A_MIN_READS = "min_reads"
    A_MEAN_RL = "mean_read_length"
    A_MEAN_MAX_SRL = "mean_longest_subread_length"
    A_NREADS_BARCODED = "n_barcoded_reads"
    A_NREADS_UNBARCODED = "n_unbarcoded_reads"

    C_BIOSAMPLE = "biosample"
    C_IDX = "barcode_index"
    C_BARCODE = 'barcode'
    C_NREADS = 'number_of_reads'
    C_NSUBREADS = 'number_of_subreads'
    C_NBASES = 'number_of_bases'
    C_READLENGTH = "mean_read_length"
    C_SRL = "longest_subread_length"
    C_BCQUAL = "mean_bcqual"
    C_RANK = "rank_order"
    C_UUID = "dataset_uuid" # XXX test only

    PG_STATS = "read_stats"
    P_NREADS = "nreads"
    P_HIST_NREADS = "nreads_histogram"
    P_HIST_RL = "readlength_histogram"

    PG_BQ = "bq_plots"
    P_HIST_BQ = "bq_histogram"
    P_BQ_QQ = "bq_qq"

    PG_HIST2D = "hist2d"
    P_HIST2D_RL = "binned_readlength"
    P_HIST2D_BQ = "binned_bcqual"
    BQ_BINS = 50
    RL_BIN_WIDTH = 1000

    SHOW_COLUMNS = [
        C_BIOSAMPLE,
        C_IDX,
        C_BARCODE,
        C_NREADS,
        C_NSUBREADS,
        C_NBASES,
        C_READLENGTH,
        C_SRL,
        C_BCQUAL,
        C_RANK
    ]

    SHOW_ATTRIBUTES = [
        A_NBARCODES,
        A_NREADS_BARCODED,
        A_NREADS_UNBARCODED,
        A_MEAN_READS,
        A_MAX_READS,
        A_MIN_READS,
        A_MEAN_RL,
        A_MEAN_MAX_SRL
    ]

    VALID_FT_IDS = {
        FileTypes.DS_SUBREADS.file_type_id,
        FileTypes.DS_CCS.file_type_id
    }

    PLOTLY_COLORSCALE = [['0', 'rgb(180,180,180)'], ['0.001', 'rgb(82,82,255)'], ['0.25', 'rgb(80,236,186)'], [
        '0.5', 'rgb(255,255,100)'], ['0.75', 'rgb(242,163,76)'], ['1', 'rgb(255,80,80)']]


def _to_plot(fig, plot_id, base_dir):
    img_name = plot_id + ".png"
    _, thumb_name = save_figure_with_thumbnail(
        fig, op.join(base_dir, img_name))
    return Plot(plot_id, img_name, thumbnail=op.basename(thumb_name))


def _make_readlength_hist2d_plotly(x, y, bc_groups, base_dir,
                                   xlabel="Barcode Rank Order By Read Count",
                                   ylabel="Read Length",
                                   title="Barcoded Read Length Distribution"):
    # TODO figure out binning
    y_bins = []
    max_len = max(1, max(y) if len(y) > 0 else 1)
    k = 0
    while k < max_len:
        k += Constants.RL_BIN_WIDTH
        y_bins.append(k)
    heatmap = to_sample_heatmap(x, y,
                                sample_labels=[g.label for g in bc_groups],
                                y_bins=y_bins,
                                yrange=(0, max_len),
                                colorscale=Constants.PLOTLY_COLORSCALE)
    layout = to_simple_layout(xlabel, ylabel, title)
    file_name = op.join(
        base_dir, "{i}.json.gz".format(i=Constants.P_HIST2D_RL))
    return to_plotly_plot(Constants.P_HIST2D_RL, file_name, heatmap, layout)


def _get_xy(iterable):
    """
    Given an iterable that yields alternating X and Y integer values, return
    the corresponding numpy arrays (actually views on a single array).
    """
    data = np.fromiter(iterable, int)
    return data[0::2], data[1::2]


def make_readlength_hist2d(bc_groups, base_dir, plot_spec):
    """
    Create 2D histogram of read lengths per barcoded sample.
    """
    log.info("Creating 2D histogram of read lengths")

    def _iter_readlengths():
        for i, group in enumerate(bc_groups, start=1):
            for j, readlength in enumerate(group.readlengths):
                yield i
                yield readlength
    x, y = _get_xy(_iter_readlengths())
    return _make_readlength_hist2d_plotly(x, y, bc_groups, base_dir,
                                          xlabel=plot_spec.xlabel,
                                          ylabel=plot_spec.ylabel,
                                          title=plot_spec.title)


def _make_bcqual_hist2d_plotly(x, y, bc_groups, base_dir,
                               xlabel="Barcode Rank Order By Read Count",
                               ylabel="Read Barcode Quality Score",
                               title="Barcode Read Quality Distribution"):
    """
    Plotly implementation of barcode quality heatmap.
    """
    heatmap = to_sample_heatmap(x, y,
                                sample_labels=[g.label for g in bc_groups],
                                y_bins=list(range(2, 102, 2)),
                                yrange=(1, 100),
                                colorscale=Constants.PLOTLY_COLORSCALE)
    layout = to_simple_layout(xlabel, ylabel, title)
    file_name = op.join(
        base_dir, "{i}.json.gz".format(i=Constants.P_HIST2D_BQ))
    return to_plotly_plot(Constants.P_HIST2D_BQ, file_name, heatmap, layout)


def make_bcqual_hist2d(bc_groups, base_dir, plot_spec):
    """
    Create 2D histogram of barcode quality scores per barcoded sample.
    """
    log.info("Creating 2D histogram of barcode quality scores")

    def _iter_bcqual():
        for i, group in enumerate(bc_groups, start=1):
            for j, bq in enumerate(group.bqs):
                yield i
                yield bq
    x, y = _get_xy(_iter_bcqual())
    return _make_bcqual_hist2d_plotly(x, y, bc_groups, base_dir,
                                      xlabel=plot_spec.xlabel,
                                      ylabel=plot_spec.ylabel,
                                      title=plot_spec.title)


def make_nreads_line_plot(bc_groups, base_dir, plot_spec):
    x = [i for (i, g) in enumerate(bc_groups, start=1)]
    y = [g.n_reads for g in bc_groups]
    mean_nreads = 0 if len(y) == 0 else sum(y) / len(y)
    fig, ax = get_fig_axes_lpr()
    ax.plot(x, y, color='blue')
    line = ax.axhline(mean_nreads, color='red', label="Mean Number of Reads")
    ax.set_xlabel(plot_spec.xlabel)
    ax.set_ylabel(plot_spec.ylabel)
    fig.legend((line,), ("Mean Number of Reads",), ("upper right"))
    return _to_plot(fig, Constants.P_NREADS, base_dir)


def make_nreads_histogram(bc_groups, base_dir, plot_spec):
    """
    Create simple histogram of read count frequency per barcode.
    """
    fig, ax = make_histogram(
        datum=[float(g.n_reads) for g in bc_groups],  # FIXME workaround
        axis_labels=[plot_spec.xlabel, plot_spec.ylabel],
        nbins=min(len(bc_groups), 20),
        barcolor=get_blue(3))
    return _to_plot(fig, Constants.P_HIST_NREADS, base_dir)


def make_readlength_histogram(bc_groups, base_dir, plot_spec):
    """
    Create simple histogram of read length frequency per barcode.
    """
    fig, ax = make_histogram(
        datum=[float(g.mean_read_length()) for g in bc_groups],  # FIXME
        axis_labels=[plot_spec.xlabel, plot_spec.ylabel],
        nbins=min(len(bc_groups), 20),
        barcolor=get_blue(3))
    return _to_plot(fig, Constants.P_HIST_RL, base_dir)


def make_bcqual_histogram(bc_groups, base_dir, plot_spec,
                          min_bq_filter=Constants.MIN_BQ_FILTER):
    """
    Create simple histogram of barcode quality score frequency over all
    barcoded subreads.
    """
    data = []
    for g in bc_groups:
        data.extend(g.bqs)
    fig, ax = make_histogram(
        datum=data,
        axis_labels=[plot_spec.xlabel, plot_spec.ylabel],
        nbins=50,
        barcolor=get_blue(3))
    ax.axvline(min_bq_filter, color='r')
    return _to_plot(fig, Constants.P_HIST_BQ, base_dir)


def make_bq_qq_plot(bc_groups, base_dir):
    """
    Create Q-Q plot for barcode quality scores.
    """
    try:
        import scipy.stats
    except ImportError:
        warnings.warn("Can't import scipy.stats")
        return None
    else:
        data = []
        for g in bc_groups:
            data.append(g.mean_bcqual())
        fig, ax = get_fig_axes_lpr()
        scipy.stats.probplot(data, dist="norm", plot=ax)
        ax.set_title("Q-Q Plot of Barcode Quality Scores")
        return _to_plot(fig, Constants.P_BQ_QQ, base_dir)


def make_plots(bc_groups, base_dir, use_spec=spec,
               label_none=Constants.LABEL_NONE,
               min_bq_filter=Constants.MIN_BQ_FILTER):
    """
    Generate all plots, both 1D and 2D, and return a list of PlotGroups.
    """
    groups = [g for g in bc_groups if g.label != label_none]
    groups.sort(lambda a, b: cmp(b.n_reads, a.n_reads))
    plot_nreads = make_nreads_line_plot(groups, base_dir,
                                        use_spec.get_plot_spec(Constants.PG_STATS, Constants.P_NREADS))
    log.info("Generating 1D histograms...")
    plot_nreads_hist = make_nreads_histogram(groups, base_dir,
                                             use_spec.get_plot_spec(Constants.PG_STATS, Constants.P_HIST_NREADS))
    plot_rl = make_readlength_histogram(groups, base_dir,
                                        use_spec.get_plot_spec(Constants.PG_STATS, Constants.P_HIST_RL))
    log.info("Generating barcode quality score plots...")
    plot_bq = make_bcqual_histogram(groups, base_dir,
                                    use_spec.get_plot_spec(Constants.PG_BQ, Constants.P_HIST_BQ),
                                    min_bq_filter=min_bq_filter)
    bq_plots = [plot_bq]
    log.info("Generating 2D histograms...")
    plot_rl2d = make_readlength_hist2d(groups, base_dir,
                                       use_spec.get_plot_spec(Constants.PG_HIST2D, Constants.P_HIST2D_RL))
    plot_bq = make_bcqual_hist2d(groups, base_dir,
                                 use_spec.get_plot_spec(Constants.PG_HIST2D, Constants.P_HIST2D_BQ))
    return [
        PlotGroup(Constants.PG_STATS, plots=[
                  plot_nreads, plot_nreads_hist, plot_rl]),
        PlotGroup(Constants.PG_BQ, plots=bq_plots),
        PlotGroup(Constants.PG_HIST2D, plots=[plot_rl2d, plot_bq])
    ]


def _get_barcoded_datasets(reads_file):
    reads_file = op.realpath(reads_file)
    dir_name = op.dirname(reads_file)
    if reads_file.endswith(".datastore.json"):
        datastore = DataStore.load_from_json(reads_file)
        datasets = [f.path for u, f in datastore.files.iteritems()
                    if f.file_type_id in Constants.VALID_FT_IDS]
        if len(datasets) == 0:
            raise ValueError("No datasets containing barcoded reads were "
                             + "present in the input.  This could mean that "
                             + "demultiplexing was run with incorrect inputs "
                             + "or an overly restrictive minimum barcode score.")
        return datasets
    else:
        return [reads_file]


def _make_demuxed_dataset_report(ds, output_dir):
    ds_rpt_dir = op.join(output_dir, ds.uuid)
    if not op.exists(ds_rpt_dir):
        os.makedirs(ds_rpt_dir)
    # NOTE the source_id field will determine the reportTypeId field in the
    # corresponding SL API job report model.  making these distinct from the
    # parent barcoding report source_id gives us a way to blacklist them in
    # the UI when displaying analysis results
    if isinstance(ds, SubreadSet):
        rpt = subread_stats.make_report(ds, ds_rpt_dir)
        source_id = "pbreports.tasks.subread_stats-out-0"
    elif isinstance(ds, ConsensusReadSet):
        rpt = ccs2.make_report(ds, ds_rpt_dir,
                               constants=ccs2.ConstantsDemultiplexed)
        # XXX hacky - no actual task/module with this name exists
        source_id = "pbreports.tasks.ccs_demux_stats-out-0"
    rpt_file = op.join(ds_rpt_dir, "dataset_stats.json")
    log.info("Writing sub-report to %s", rpt_file)
    rpt.write_json(rpt_file)
    return DataStoreFile(
        uuid=rpt.uuid,
        source_id=source_id,
        type_id=FileTypes.REPORT.file_type_id,
        path=op.abspath(rpt_file),
        is_chunked=False,
        name="Dataset report")


def _get_single_dataset_info(dataset_file, barcodes_file, subrpt_output_dir,
                             isoseq_mode=False):
    with openDataSet(dataset_file) as ds_bc:
        ds_bc.disableFilters()
        datastore_file = None
        if subrpt_output_dir is not None:
            datastore_file = _make_demuxed_dataset_report(
                ds_bc, subrpt_output_dir)
        biosamples = get_biosample_dict(ds_bc)
        with BarcodeSet(barcodes_file) as barcodes:
            for er in ds_bc.externalResources:
                for er2 in er.externalResources:
                    if (er2.metaType == DataSetMetaTypes.BARCODE
                            and er2.uniqueId != barcodes.uuid) :
                        raise ValueError(
                            "UniqueId mismatch between external resource "
                            + "barcodes and input BarcodeSet: "
                            + "{a} != {b}".format(a=er2.uniqueId,
                                                b=barcodes.uuid))
            log.info("Extracting barcoded read info from input dataset")
            return get_reads_by_barcode(ds_bc.index, barcodes, isoseq_mode=isoseq_mode), biosamples, datastore_file, ds_bc.uuid


def __get_single_dataset_info(args):
    (dataset_file, barcodes_file, output_dir, isoseq_mode) = args
    return _get_single_dataset_info(dataset_file, barcodes_file,
                                    subrpt_output_dir=output_dir,
                                    isoseq_mode=isoseq_mode)


def get_barcode_info_parallel(dataset_files, barcodes_file, nproc=1,
                              subrpt_output_dir=None,
                              isoseq_mode=False):  # pragma: nocov
    args = [(f, barcodes_file, subrpt_output_dir, isoseq_mode) for f in dataset_files]
    results = pool_map(__get_single_dataset_info, args, nproc)
    bc_info = []
    biosamples = {}
    barcoded_zmws = set()
    datastore_files = []
    bc_dataset_uuids = {} # XXX for testing purposes
    for chunk_bc_info, chunk_biosamples, datastore_file, uuid in results:
        bc_info.extend(chunk_bc_info)
        barcoded_zmws.update({(r.qId, r.holeNumber) for r in chunk_bc_info})
        biosamples.update(chunk_biosamples)
        datastore_files.append(datastore_file)
        if len(chunk_biosamples) > 0:
            bc_dataset_uuids[chunk_biosamples.keys()[0]] = uuid
    return bc_info, barcoded_zmws, biosamples, datastore_files, bc_dataset_uuids


def _make_report_impl(attribute_ids,
                      column_ids,
                      label_none,
                      biosamples,
                      read_info,
                      bc_dataset_uuids,
                      dataset_uuids=(),
                      base_dir=None,
                      use_spec=spec,
                      with_attributes=(),
                      min_bq_filter=Constants.MIN_BQ_FILTER,
                      test_mode=False):
    """
    Create a Report object starting from an iterable of ReadInfo objects.
    """
    log.info("Creating report files...")
    if base_dir == None:
        base_dir = os.getcwd()

    bc_groups = {}
    bc_info = defaultdict(list)

    for bc_read in read_info:
        bc_info[bc_read.label].append(bc_read)
        if not bc_read.label in bc_groups:
            bc_groups[bc_read.label] = BarcodeGroup(
                bc_read.label, idx=bc_read.idx)
        bc_groups[bc_read.label].add_read(bc_read)

    table = Table('barcode_table',
                  columns=[Column(column_id) for column_id in column_ids])
    if test_mode:
        table.columns.append(Column(Constants.C_UUID))

    def add_column_if_present(column_id, value):
        if column_id in column_ids:
            table.add_data_by_column_id(column_id, value)

    labels = sorted(bc_groups.keys())
    labels_bc = list(labels)  # this will only contain actual barcodes
    if label_none in labels:
        labels.remove(label_none)
        labels_bc = list(labels)
        labels.append(label_none)
    rank = {}
    k = 0
    groups = sorted(bc_groups.values(), lambda a, b: cmp(b.n_reads, a.n_reads))
    for bc_group in groups:
        if bc_group.label != label_none:
            k += 1
            rank[bc_group.label] = k
    n_barcodes = len(labels_bc)
    n_barcoded_reads = n_unbarcoded_reads = 0
    for label in labels:
        row = bc_groups[label]
        add_column_if_present(Constants.C_BIOSAMPLE, biosamples.get(
            label, Constants.BIOSAMPLE_NONE))
        add_column_if_present(Constants.C_IDX, row.idx)
        add_column_if_present(Constants.C_BARCODE, label)
        add_column_if_present(Constants.C_NREADS, row.n_reads)
        add_column_if_present(Constants.C_NSUBREADS, row.n_subreads)
        add_column_if_present(Constants.C_NBASES, row.n_bases)
        add_column_if_present(
            Constants.C_READLENGTH, row.mean_read_length())
        add_column_if_present(Constants.C_SRL, row.mean_longest_subread_length())
        add_column_if_present(Constants.C_BCQUAL, row.mean_bcqual())
        add_column_if_present(Constants.C_RANK, rank.get(label, None))
        if label == label_none:
            n_unbarcoded_reads += row.n_reads
        else:
            n_barcoded_reads += row.n_reads
        if test_mode:
            table.add_data_by_column_id(Constants.C_UUID,
                                        bc_dataset_uuids.get(label, "None"))

    attr = list(with_attributes)

    def add_attribute_if_present(attr_id, value):
        if attr_id in attribute_ids:
            attr.append((attr_id, value))

    add_attribute_if_present(Constants.A_NBARCODES, n_barcodes)
    add_attribute_if_present(Constants.A_NREADS_BARCODED, n_barcoded_reads)
    if n_barcodes > 0:
        n_reads_all = [bc_groups[k].n_reads for k in labels_bc]
        n_reads_sum = sum(n_reads_all)
        #rl_sum = sum([bc_groups[k].bases for k in labels_bc])
        srl_max_sum = rl_sum = 0
        for k in labels_bc:
            rl_sum += sum([b.readlength for b in bc_info[k]])
            srl_max_sum += max([b.srl_max for b in bc_info[k]])
        srl_max_mean = mean_int(sum([bc_groups[k].mean_longest_subread_length() for k in labels_bc]), n_barcodes)
        attr.extend([
            (Constants.A_MEAN_READS, int(n_reads_sum / n_barcodes)),
            (Constants.A_MAX_READS, max(n_reads_all)),
            (Constants.A_MIN_READS, min(n_reads_all)),
            # XXX these need to be clarified
        ])
        add_attribute_if_present(
            Constants.A_MEAN_RL, int(rl_sum / n_reads_sum))
        add_attribute_if_present(Constants.A_MEAN_MAX_SRL, srl_max_mean)
    else:
        attr.extend([(ID, 0) for ID in attribute_ids[3:]])
    add_attribute_if_present(Constants.A_NREADS_UNBARCODED, n_unbarcoded_reads)

    plotgroups = make_plots(bc_groups.values(), base_dir, use_spec,
                            min_bq_filter=min_bq_filter)

    attributes = [Attribute(id_, value=val) for (id_, val) in attr]
    report = Report(use_spec.id,
                    attributes=attributes,
                    tables=[table],
                    dataset_uuids=dataset_uuids,
                    plotgroups=plotgroups)
    return use_spec.apply_view(report)


make_report = functools.partial(
    _make_report_impl, Constants.SHOW_ATTRIBUTES, Constants.SHOW_COLUMNS,
    Constants.LABEL_NONE)


def save_demuxed_dataset_reports(datastore_files, output_dir, datastore_json):
    datastore = DataStore(datastore_files)
    datastore.write_json(datastore_json)
    log.info("Wrote datastore to %s", datastore_json)


def write_empty_datastore(datastore_json):
    """
    Generate an empty datastore JSON if required by the tool contract
    interface but we have no sub-reports to save.
    """
    if datastore_json is not None:
        datastore = DataStore([])
        datastore.write_json(datastore_json)
        log.info("Wrote empty datastore to %s", datastore_json)


def read_inputs(ds_bc_file, barcodes_file, reads_in_file):
    ReportInputs = namedtuple("ReportInputs", [
                              "ds_files", "reads_in", "barcodes", "dataset_uuids", "is_subreads"])
    ds_files = _get_barcoded_datasets(ds_bc_file)
    reads_in = openDataSet(reads_in_file, strict=True)
    barcodes = BarcodeSet(barcodes_file)
    dataset_uuids = [
        barcodes.uuid,
        reads_in.uuid
    ]  # not including demuxed datasets - see SL-3646
    is_subreads = True
    if len(ds_files) > 0:
        md = get_dataset_metadata(ds_files[0])
        is_subreads = md.metatype == FileTypes.DS_SUBREADS.file_type_id
    return ReportInputs(ds_files, reads_in, barcodes, dataset_uuids, is_subreads)


def run_to_report(ds_bc_file, barcodes_file, reads_in_file, base_dir=None,
                  datastore_json=None, nproc=1, test_mode=False,
                  min_bq_filter=Constants.MIN_BQ_FILTER):
    """
    Generate a Report instance from a SubreadSet and BarcodeSet.
    """
    if base_dir is None:
        base_dir = os.getcwd()
    inputs = read_inputs(ds_bc_file, barcodes_file, reads_in_file)
    subrpt_output_dir = None
    if datastore_json is not None:
        if inputs.is_subreads:
            subrpt_output_dir = op.join(base_dir, "sub_reports")
        else:
            write_empty_datastore(datastore_json)
    read_info, barcoded_zmws, biosamples, datastore_files, bc_dataset_uuids = get_barcode_info_parallel(
        inputs.ds_files,
        barcodes_file,
        nproc=nproc,
        subrpt_output_dir=subrpt_output_dir)
    if subrpt_output_dir is not None:
        save_demuxed_dataset_reports(
            datastore_files, base_dir, datastore_json)
    log.info("Identifying non-barcoded reads...")
    read_info.extend(
        list(get_unbarcoded_reads_info(inputs.reads_in, barcoded_zmws)))
    return make_report(biosamples=biosamples,
                       read_info=read_info,
                       dataset_uuids=inputs.dataset_uuids,
                       bc_dataset_uuids=bc_dataset_uuids,
                       base_dir=base_dir,
                       use_spec=spec,
                       test_mode=test_mode,
                       min_bq_filter=min_bq_filter)


def args_runner(args):
    log.info("Starting {f} version {v} report generation".format(
        f=__file__, v=__version__))
    report = run_to_report(args.ds_bc, args.barcodes, args.reads_in,
                           base_dir=op.dirname(args.report_json),
                           datastore_json=args.dataset_reports,
                           nproc=args.nproc,
                           test_mode=args.test_mode,
                           min_bq_filter=args.min_bq_filter)
    log.info(pformat(report.to_dict()))
    report.write_json(args.report_json)
    report.tables[0].to_csv(args.report_csv)
    return 0


def resolved_tool_contract_runner(rtc):
    log.info("Starting {f} version {v} report generation".format(
        f=__file__, v=__version__))
    report = run_to_report(
        ds_bc_file=rtc.task.input_files[0],
        barcodes_file=rtc.task.input_files[2],
        reads_in_file=rtc.task.input_files[1],
        base_dir=op.abspath(op.dirname(rtc.task.output_files[0])),
        datastore_json=rtc.task.output_files[2],
        nproc=rtc.task.nproc)
    log.debug(pformat(report.to_dict()))
    report.write_json(rtc.task.output_files[0])
    report.tables[0].to_csv(rtc.task.output_files[1])
    return 0


def get_parser(constants=Constants, include_datastore_json=True):
    p = get_pbparser(
        tool_id=constants.TOOL_ID,
        version=constants.VERSION,
        name=constants.TOOL_NAME,
        description=constants.DOC,
        driver_exe=constants.DRIVER_EXE,
        is_distributed=True,
        nproc=Constants.MAX_NPROC)
    p.add_input_file_type(
        FileTypes.DATASTORE,
        "ds_bc",
        name="JSON Datastore or SubreadSet or ConsensusReadSet",
        description="Datastore of barcoded SubreadSet/ConsensusReadSet files")
    p.add_input_file_type(constants.FILE_TYPE_READS_IN, "reads_in",
                          name="Input SubreadSet or ConsensusReadSet",
                          description="Input SubreadSet or ConsensusReadSet (without barcodes)")
    p.add_input_file_type(FileTypes.DS_BARCODE, "barcodes",
                          name="BarcodeSet",
                          description="Barcode DataSet XML")
    p.add_output_file_type(FileTypes.REPORT, "report_json",
                           name="Barcode Report",
                           description="Summary of barcoding results",
                           default_name="barcode_report")
    p.add_output_file_type(
        FileTypes.CSV, "report_csv",
        name="Barcode Report Details",
        description="Barcode Details Table as CSV",
        default_name="barcodes_report")
    if include_datastore_json:
        p.add_output_file_type(
            FileTypes.DATASTORE,
            "dataset_reports",
            name="Datastore JSON",
            description="Datastore of individual SubreadSet reports",
            default_name="dataset_reports")
    p.arg_parser.parser.add_argument(
        "--min-bq-filter",
        action="store",
        type=int,
        default=Constants.MIN_BQ_FILTER,
        help="Minimum barcode quality encoded in dataset filter")
    p.arg_parser.parser.add_argument(
        "-n", "--nproc", action="store", default=1,
        help="Number of processors to use")
    p.arg_parser.parser.add_argument(
        "--test-mode", action="store_true", default=False,
        help="Generate additional table used for integration testing (DEVELOPER FEATURE ONLY)")
    return p


def main(argv=sys.argv):
    return pbparser_runner(
        argv=argv[1:],
        parser=get_parser(),
        args_runner_func=args_runner,
        contract_runner_func=resolved_tool_contract_runner,
        alog=log,
        setup_log_func=setup_log)


if __name__ == '__main__':
    sys.exit(main())
