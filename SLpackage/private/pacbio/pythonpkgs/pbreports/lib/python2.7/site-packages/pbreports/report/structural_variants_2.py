
"""
Structural Variants 2 Report
"""

import logging
import sys
import json
import itertools
import collections

from collections import namedtuple

import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
import matplotlib.ticker as ticker
from matplotlib import rcParams
from matplotlib.transforms import offset_copy

from pbcommand.models.report import Report, Table, Column, PlotGroup, Plot
from pbcommand.models import FileTypes, get_pbparser
from pbcommand.cli import pbparser_runner
from pbcommand.utils import setup_log
from pbreports.io.specs import *
from pbreports.plot.helper import (get_fig_axes_lpr,
                                   save_figure_with_thumbnail, DEFAULT_DPI)

__version__ = '0.1.0'


log = logging.getLogger(__name__)


class Constants(object):
    TOOL_ID = "pbreports.tasks.structural_variants_2_report"
    DRIVER_EXE = ("python -m pbreports.report.structural_variants_2 "
                  "--resolved-tool-contract ")
    R_ID = "structural_variants_2"

    SAMPLE_KEY = "sv_samples"
    T_SAMPLE_SV = "sv_sample_table"
    T_SAMPLE_GENO = "geno_sample_table"
    C_SAMPLE = "sample"
    C_INS = "insertions"
    C_DEL = "deletions"
    C_HOM = "homozygous"
    C_HET = "heterozygous"
    C_INV = "inversions"
    C_TRA = "translocations"
    C_DUP = "duplications"
    C_TOTAL = "total"

    SAMPLE = "sample_name"
    INSERTIONS_COUNT = "insertion_counts"
    INSERTIONS_BP = "insertion_bp"
    DELETIONS_COUNT = "deletion_counts"
    DELETIONS_BP = "deletion_bp"
    INVERSIONS_COUNT = "inversion_counts"
    INVERSIONS_BP = "inversion_bp"
    TRANSLOCATIONS_COUNT = "translocation_counts"
    DUPLICATIONS_COUNT = "duplication_counts"
    DUPLICATIONS_BP = "duplication_bp"
    HOMOZYGOUS_COUNT = "homozygous_counts"
    HETEROZYGOUS_COUNT = "heterozygous_counts"
    TOTAL_COUNT = "total_counts"
    TOTAL_BP = "total_bp"

    ANNO_KEY = "sv_annotations"
    T_ANNO = "anno_table"
    C_ANNO = "annotation"
    ANNOTATION_TYPE = "annotation_type"
    R_TANDEM = "Tandem Repeat"
    R_ALU = "ALU"
    R_L1 = "L1"
    R_SVA = "SVA"
    R_UNANNOTATED = "Unannotated"
    R_TOTAL = "Total"

    PG_SV = "sv_plot_group"
    P_SV = "sv_plot"
    C_TINY = 'Variants <100 bp'
    C_SHORT = 'Variants 100-999 bp'
    C_LONG = 'Variants ' + r'$\geq$' + '1 kb'
    D_INS = "Insertion"
    D_DEL = "Deletion"

    SV_LEN_CUTOFF_T = 100
    BIN_WIDTH_T = 1
    X_TICKS_T = range(0, SV_LEN_CUTOFF_T + 10, 5)[:-1]
    X_LIMS_T = [X_TICKS_T[0], X_TICKS_T[-1]]
    X_LABELS_T = list(itertools.chain(
        *[[str(x), "", "", ""] for x in xrange(0, SV_LEN_CUTOFF_T + 20, 20)]))
    X_LABEL_T = "variant length (bp)"
    N_BINS_T = X_LIMS_T[1] / BIN_WIDTH_T

    SV_LEN_CUTOFF_S = 1000
    BIN_WIDTH_S = 10
    X_TICKS_S = range(0, SV_LEN_CUTOFF_S + 100, 50)[:-1]
    X_LIMS_S = [X_TICKS_S[0], X_TICKS_S[-1]]
    X_LABELS_S = list(itertools.chain(
        *[[str(x), "", "", ""] for x in xrange(0, SV_LEN_CUTOFF_S, 200)])) + ["1,000"]
    X_LABEL_S = "variant length (bp)"
    N_BINS_S = X_LIMS_S[1] / BIN_WIDTH_S

    OVERFLOW_BIN_X = 11250
    SV_LEN_CUTOFF_L = 10000
    BIN_WIDTH_L = 100
    X_TICKS_L = range(0, SV_LEN_CUTOFF_L + 500,
                      500) + [OVERFLOW_BIN_X]
    X_LIMS_L = [0, 12000]
    X_LABELS_L = list(itertools.chain(
        *[[str(x), "", "", ""] for x in xrange(0, 10, 2)]))[:-1] + ["", "10", ">10"]
    X_LABEL_L = "variant length (kb)"
    N_BINS_L = X_LIMS_L[1] / BIN_WIDTH_L


class SvAnnotation(namedtuple("SvAnnotation",
                              [Constants.ANNOTATION_TYPE,
                               Constants.INSERTIONS_COUNT, Constants.INSERTIONS_BP,
                               Constants.DELETIONS_COUNT, Constants.DELETIONS_BP,
                               Constants.TOTAL_COUNT, Constants.TOTAL_BP])):
    @staticmethod
    def from_dict(d):
        """
        :param d
        :type d dict

        :rtype SvAnnotation

        """
        # Because the field names are the same,  we're absusing python a bit here.
        # if the field names change, or the IO layer changes, this would be the place to deal
        # with these interface changes of the IO layer
        return SvAnnotation(**d)


class SvSample(namedtuple('SvSample',
                          [Constants.SAMPLE, Constants.INSERTIONS_COUNT, Constants.INSERTIONS_BP,
                           Constants.DELETIONS_COUNT, Constants.DELETIONS_BP,
                           Constants.INVERSIONS_COUNT, Constants.INVERSIONS_BP,
                           Constants.TRANSLOCATIONS_COUNT,
                           Constants.DUPLICATIONS_COUNT, Constants.DUPLICATIONS_BP,
                           Constants.HOMOZYGOUS_COUNT, Constants.HETEROZYGOUS_COUNT,
                           Constants.TOTAL_COUNT, Constants.TOTAL_BP])):

    @staticmethod
    def from_dict(d):
        # see comments above in SvAnnotation
        return SvSample(**d)


class Svann(object):

    def __init__(self, annotations, samples):
        """
        :type samples: list[SvSample]
        :type annotations: list[SvAnnotation]
        :param annotations:
        :param samples:
        """
        # explicitly defining as class to get annotations.
        self.annotations = annotations
        self.samples = samples

    @staticmethod
    def from_dict(d):
        annotations = [SvAnnotation.from_dict(
            s_d) for s_d in d['sv_annotations']]
        samples = [SvSample.from_dict(s_d) for s_d in d['sv_samples']]
        return Svann(annotations, samples)

    @staticmethod
    def from_file(path):
        with open(path, 'r') as f:
            s = Svann.from_dict(json.load(f))
        return s


class SvLength(object):

    def __init__(self, ix, insertions, deletions):
        """

        :type ix: str
        :type insertions: list[int]
        :type deletions: list[int]

        :param ix: Sample id
        :param insertions:
        :param deletions:
        """
        self.ix = ix
        self.insertions = insertions
        self.deletions = deletions


def load_sv_lengths(path):
    """
    :rtype lengths dict[str, SvLength]
    """
    with open(path, 'r') as f:
        d = json.load(f)
        # This might need to be an ordered dict?
    svs = {k: SvLength(k, v.get('Insertion', []), v.get('Deletion', []))
           for k, v in d.iteritems()}
    return svs


spec = load_spec(Constants.R_ID)


def _comma_formatter(x, pos=0):
    return ("{0:,d}".format(int(x)))


def _my_combine(n, t):
    """
    Takes two integers, n and t, and returns "n (t)"
    """
    c = _comma_formatter(str(n)) + " (" + _comma_formatter(str(t)) + ")"
    return c


def to_sv_sample_table(samples):
    """
    :type samples list[SvSample]
    :param samples
    :rtype Table
    """

    col_ids = [Constants.C_SAMPLE, Constants.C_INS, Constants.C_DEL,
               Constants.C_INV, Constants.C_TRA, Constants.C_DUP, Constants.C_TOTAL]
    t = []
    if len(samples) == 0:
        table = [[] for _ in range(len(col_ids))]
    else:
        f = _my_combine
        for sample in samples:
            r = [sample.sample_name]
            r.append(f(sample.insertion_counts, sample.insertion_bp))
            r.append(f(sample.deletion_counts, sample.deletion_bp))
            r.append(f(sample.inversion_counts, sample.inversion_bp))
            r.append(sample.translocation_counts)
            r.append(f(sample.duplication_counts, sample.duplication_bp))
            r.append(f(sample.total_counts, sample.total_bp))
            t.append(r)
        table = zip(*t)
    columns = []
    for i, col_id in enumerate(col_ids):
        columns.append(Column(col_id, values=table[i]))
    sample_table = Table(Constants.T_SAMPLE_SV, columns=columns)

    return sample_table


def to_geno_sample_table(samples):
    """
    :type samples list[SvSample]
    :param samples
    :rtype Table
    """
    col_ids = [Constants.C_SAMPLE, Constants.C_HOM,
               Constants.C_HET, Constants.C_TOTAL]

    t = []
    if len(samples) == 0:
        table = [[], [], [], []]
    else:
        for sample in samples:
            r = [sample.sample_name, sample.homozygous_counts,
                 sample.heterozygous_counts, sample.total_counts]
            t.append(r)
        table = zip(*t)
    columns = []
    for i, col_id in enumerate(col_ids):
        columns.append(Column(col_id, values=table[i]))
    sample_table = Table(Constants.T_SAMPLE_GENO, columns=columns)

    return sample_table


def to_anno_table(annotations):
    """
    :type annotations list[SvAnnotation]
    :param annotations
    :rtype Table
    """
    col_ids = [Constants.C_ANNO, Constants.C_INS,
               Constants.C_DEL, Constants.C_TOTAL]
    row_ids = [Constants.R_TANDEM, Constants.R_ALU, Constants.R_L1,
               Constants.R_SVA, Constants.R_UNANNOTATED, Constants.R_TOTAL]
    if len(annotations) == 0:
        table = [[] for _ in range(len(col_ids))]
    else:
        t = []
        f = _my_combine
        for _id in row_ids:
            for ax in annotations:
                log.info(ax)
                if _id == ax.annotation_type:
                    r = [ax.annotation_type]
                    r.append(f(ax.insertion_counts, ax.insertion_bp))
                    r.append(f(ax.deletion_counts, ax.deletion_bp))
                    r.append(f(ax.total_counts, ax.total_bp))
                    t.append(r)
        table = zip(*t)
    columns = []
    for i, col_id in enumerate(col_ids):
        columns.append(Column(col_id, values=table[i]))
    anno_table = Table(Constants.T_ANNO, columns=columns)

    return anno_table


def _process_tiny_data(sv_length):
    """
    :type sv_length SvLength
    """
    tiny_ins = [x for x in sv_length.insertions if 9 < x < 100]
    tiny_del = [x for x in sv_length.deletions if 9 < x < 100]

    return tiny_ins, tiny_del


def _process_short_data(sv_length):
    """
    :type sv_length SvLength
    """
    short_ins = [x for x in sv_length.insertions if 99 <
                 x < Constants.SV_LEN_CUTOFF_S]
    short_del = [x for x in sv_length.deletions if 99 <
                 x < Constants.SV_LEN_CUTOFF_S]

    return short_ins, short_del


def _process_long_data(sv_length):
    """
    :type sv_length SvLength
    """
    long_ins_raw = [x for x in sv_length.insertions if x >=
                    Constants.SV_LEN_CUTOFF_S]
    long_del_raw = [x for x in sv_length.deletions if x >=
                    Constants.SV_LEN_CUTOFF_S]
    # mapping all lengths above 10k to a constant
    long_ins = [Constants.OVERFLOW_BIN_X if x > Constants.SV_LEN_CUTOFF_L
                else x for x in long_ins_raw]
    long_del = [Constants.OVERFLOW_BIN_X if x > Constants.SV_LEN_CUTOFF_L
                else x for x in long_del_raw]

    return long_ins, long_del


def add_subplot(fig, n_samples, sample, data, counter, y_max, position):
    insertions = data[0]
    deletions = data[1]
    y_label = get_plot_ylabel(spec, Constants.PG_SV, Constants.P_SV)
    if position == 0:
        x_ticks = Constants.X_TICKS_T
        x_lims = Constants.X_LIMS_T
        x_labels = Constants.X_LABELS_T
        n_bins = Constants.N_BINS_T
        x_label = Constants.X_LABEL_T
    if position == 1:
        x_ticks = Constants.X_TICKS_S
        x_lims = Constants.X_LIMS_S
        x_labels = Constants.X_LABELS_S
        n_bins = Constants.N_BINS_S
        x_label = Constants.X_LABEL_S
    if position == 2:
        x_ticks = Constants.X_TICKS_L
        x_lims = Constants.X_LIMS_L
        x_labels = Constants.X_LABELS_L
        n_bins = Constants.N_BINS_L
        x_label = Constants.X_LABEL_L
    index = counter * 3 + position + 1
    ax = fig.add_subplot(n_samples, 3, index)
    if insertions or deletions:
        ax.hist([deletions, insertions], label=["Deletions", "Insertions"], histtype='barstacked',
                color=["#FF7E79", "#A9D18E"], edgecolor="none", bins=n_bins,
                width=0.85 * (x_lims[1] - x_lims[0]) / n_bins, range=[x_lims[0], x_lims[1]])
    ax.set_xlabel(x_label, size=20)
    ax.set_ylabel(y_label, size=20)
    ax.set_ylim(bottom=0)
    ax.set_xlim(left=x_lims[0], right=x_lims[1])
    ax.yaxis.set_major_locator(ticker.MaxNLocator(integer=True))
    ax.yaxis.set_major_formatter(ticker.FuncFormatter(_comma_formatter))
    ax.grid(color='#e0e0e0', linewidth=0.9, linestyle='-')
    ax.xaxis.grid(False)
    ax.set_axisbelow(True)
    ax.set_xticks(x_ticks)
    ax.set_xticklabels(x_labels, size=15)
    ax.tick_params(axis='y', labelsize=15)
    rcParams['xtick.direction'] = 'out'
    rcParams['ytick.direction'] = 'out'
    ax.yaxis.set_ticks_position('left')
    ax.xaxis.set_ticks_position('bottom')
    y_top = ax.get_ylim()[1]
    if y_top > y_max[position]:
        y_max[position] = y_top
    if index == 1 or index == 2 or index == 3:
        label_column(ax, index)


def add_subplots(fig, n_samples, sample, sv_length, counter, y_max):
    """
    :type sv_length: SvLength
    :return:
    """

    # FIXME. Remove this duplication and pass filter functions into a general
    # process func.
    tiny_ins, tiny_del = _process_tiny_data(sv_length)
    add_subplot(fig, n_samples, sample, [tiny_ins, tiny_del], counter, y_max, 0)
    short_ins, short_del = _process_short_data(sv_length)
    add_subplot(fig, n_samples, sample, [short_ins, short_del], counter, y_max, 1)
    long_ins, long_del = _process_long_data(sv_length)
    add_subplot(fig, n_samples, sample, [long_ins, long_del], counter, y_max, 2)


def label_column(ax, index):
    pad = 5  # in points
    columns = [Constants.C_TINY, Constants.C_SHORT, Constants.C_LONG]
    ax.annotate(columns[index - 1], xy=(0.5, 1), xytext=(0, pad),
                xycoords='axes fraction', textcoords='offset points',
                size=25, ha='center', va='baseline')


def add_legend(fig):
    p1 = mpatches.Patch(color='#FF7E79', linewidth=0)
    p2 = mpatches.Patch(color='#A9D18E', linewidth=0)
    fig.legend((p1, p2), ("Deletions", "Insertions"),
               loc=2, borderpad=0.2, handlelength=1.2,
               labelspacing=0.1, handletextpad=0.3, fontsize=15)


def to_plotgroup(sv_lengths_d, output_dir):
    """
    :type sv_lengths: dict[str,SvLength]
    :param sv_lengths:
    :param output_dir:
    :rtype PlotGroup
    """

    n_samples = len(sv_lengths_d)

    if n_samples == 0:
        fig = plt.figure()
    else:
        od = collections.OrderedDict(sorted(sv_lengths_d.items()))
        fig, big_axes = plt.subplots(figsize=(15, n_samples * 5), nrows=n_samples, ncols=1, sharey=True)
        if n_samples == 1:
            big_axes = [big_axes]
        for row, big_ax in enumerate(big_axes, start=1):
            pad = 10
            if row == 1:
                pad = 40
            big_ax.set_title(od.items()[row - 1][0], fontsize=24, pad=pad)
            big_ax.tick_params(labelcolor=(1., 1., 1., 0.0), top=False, bottom=False, left=False, right=False)
            big_ax._frameon = False
        counter = 0
        y_max = [0, 0, 0]
        for s_id, sv_length in od.iteritems():
            add_subplots(fig, n_samples, '', sv_length, counter, y_max)
            counter += 1
        for row in xrange(0, n_samples):
            fig.get_axes()[row * 3 + 0 + n_samples].set_ylim(top=y_max[0] * 1.1)
            fig.get_axes()[row * 3 + 1 + n_samples].set_ylim(top=y_max[1] * 1.1)
            fig.get_axes()[row * 3 + 2 + n_samples].set_ylim(top=y_max[2] * 1.1)
        add_legend(fig)
        plt.tight_layout()
    plot_name = get_plot_title(spec, Constants.PG_SV, Constants.P_SV)
    png_fn = os.path.join(output_dir, "{p}.png".format(p=Constants.P_SV))
    png_base, thumbnail_base = save_figure_with_thumbnail(
        fig, png_fn, dpi=DEFAULT_DPI, bbox_inches='tight')
    plot = Plot(Constants.P_SV, os.path.relpath(png_base, output_dir),
                title=plot_name, caption=plot_name,
                thumbnail=os.path.relpath(thumbnail_base, output_dir))
    plot_group = PlotGroup(Constants.PG_SV, plots=[plot])

    return plot_group


def to_report(table_json_file, sv_lengths_json_file, output_dir):

    log.info("Starting {f} v{v}".format(f=os.path.basename(__file__),
                                        v=__version__))

    svann = Svann.from_file(table_json_file)
    sv_lengths = load_sv_lengths(sv_lengths_json_file)

    tables = [to_sv_sample_table(svann.samples),
              to_geno_sample_table(svann.samples),
              to_anno_table(svann.annotations)]

    plotgroups = [to_plotgroup(sv_lengths, output_dir)]
    report = Report(Constants.R_ID, tables=tables, plotgroups=plotgroups)

    return spec.apply_view(report)


def _args_runner(args):
    output_dir = os.path.dirname(args.report)
    report = to_report(args.json_table, args.json_plot, output_dir)
    report.write_json(args.report)
    return 0


def _resolved_tool_contract_runner(rtc):
    output_dir = os.path.dirname(rtc.task.output_files[0])
    report = to_report(rtc.task.input_files[0],
                       rtc.task.input_files[1],
                       output_dir)
    report.write_json(rtc.task.output_files[0])
    return 0


def _add_options_to_parser(p):
    p.add_input_file_type(
        FileTypes.JSON,
        file_id="json_table",
        name="JSON Table Data",
        description="JSON of table data (svann.json)")
    p.add_input_file_type(
        FileTypes.JSON,
        file_id="json_plot",
        name="JSON Plot Data",
        description="JSON of plot data (svlengths.json)")
    p.add_output_file_type(FileTypes.REPORT, "report", spec.title,
                           description=("Filename of JSON output report. Should be name only, "
                                        "and will be written to output dir"),
                           default_name="report")
    return p


def _get_parser():
    p = get_pbparser(
        Constants.TOOL_ID,
        __version__,
        "Report",
        __doc__,
        Constants.DRIVER_EXE,
        is_distributed=False)
    return _add_options_to_parser(p)


def main(argv=sys.argv):
    return pbparser_runner(argv[1:],
                           _get_parser(),
                           _args_runner,
                           _resolved_tool_contract_runner,
                           log,
                           setup_log)


if __name__ == "__main__":
    sys.exit(main())
