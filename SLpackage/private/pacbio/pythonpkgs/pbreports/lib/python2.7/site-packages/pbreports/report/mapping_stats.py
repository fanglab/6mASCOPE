"""
Generates a report of statistics for a PacBio AlignmentSet of subreads
mapped to a reference genome.
"""

import functools
import logging
import math
import os.path as op
import os
import sys

import numpy as np

from pbcommand.models.report import Report, Attribute, Column, Table, PlotGroup, Plot
from pbcommand.models import FileTypes, get_pbparser
from pbcommand.cli import pbparser_runner
from pbcommand.utils import setup_log, pool_map
from pbcore.io import openDataFile, IndexedBamReader, SubreadSet

from pbreports.io.mapped import (collect_pbi_alignment_metrics,
                                 combine_chunked_alignment_metrics,
                                 get_best_length_binning)
from pbreports.io.specs import load_spec
from pbreports.plot.helper import get_blue, get_green, to_plotgroup
from pbreports.plot.tools import plot_read_lengths_binned, plot_concordance_histogram, plot_mapped_concordance_vs_read_length_hist2d
from pbreports.statistics import (to_readlength_accuracy_histogram2d,
                                  combine_histogram2d)
from pbreports.util import reraise

log = logging.getLogger(__name__)

__version__ = "6.4"

spec = load_spec("mapping_stats")


class Constants(object):
    TOOL_ID = "pbreports.tasks.mapping_stats"
    DRIVER_EXE = "python -m pbreports.report.mapping_stats --resolved-tool-contract "
    MAX_NPROC = 8  # more than this is overkill due to filesystem overhead
    VERSION = __version__
    DOC = __doc__
    MAPPED_FILE_TYPE = FileTypes.DS_ALIGN
    SPEC = spec

    SUBREAD_LENGTH_BIN_SIZES = [100, 200, 500]
    MAX_POINTS = 100000000

    # Report Id
    R_ID = "mapping_stats"

    # Attribute Ids
    A_NALIGNMENTS = "mapped_alignments_n"
    A_NBASES = "mapped_bases_n"
    A_NREADS = "mapped_reads_n"
    A_READLENGTH = "mapped_readlength_mean"
    A_READLENGTH_Q95 = "mapped_readlength_q95"
    A_READLENGTH_MAX = "mapped_readlength_max"
    A_READLENGTH_N50 = "mapped_readlength_n50"

    A_NSUBREADS = "mapped_subreads_n"
    A_SUBREAD_NBASES = "mapped_subread_bases_n"
    A_SUBREAD_CONCORDANCE = "mapped_subread_concordance_mean"
    A_SUBREAD_QUALITY = "mapped_subread_read_quality_mean"
    A_SUBREAD_LENGTH = "mapped_subread_readlength_mean"
    A_SUBREAD_LENGTH_MAX = "mapped_subread_readlength_max"
    A_SUBREAD_LENGTH_N50 = "mapped_subreadlength_n50"
    A_SUBREAD_LENGTH_Q95 = "mapped_subreadlength_q95"

    A_PCT_MAPPED = "pct_bases_mapped"

    # Column ids
    C_MOVIE = "movie"
    C_READS = "mapped_reads"
    C_READLENGTH = "mapped_polymerase_read_length"
    C_READLENGTH_N50 = "mapped_polymerase_read_length_n50"
    C_SUBREADS = "mapped_subreads"
    C_SUBREAD_NBASES = "mapped_subread_base"
    C_SUBREAD_LENGTH = "mapped_subread_length"
    C_SUBREAD_CONCORDANCE = "mapped_subread_concordance"

    # Table id
    #
    T_STATS = "mapping_stats_table"

    # Plot Group ids
    PG_CONCORDANCE_HIST = "subread_concordance_group"
    PG_SUBREAD_LENGTH = "subreadlength_plot"
    PG_READLENGTH = "readlength_plot"
    PG_RAINBOW = "rainbow_plot"

    # Plot ids
    P_CONCORDANCE_HIST = "concordance_plot"
    P_SUBREAD_LENGTH = "subreadlength_plot"
    P_READLENGTH = "readlength_plot"
    P_RAINBOW = "rainbow_plot"

    PNG_SUBREAD_LENGTH = "mapped_subreadlength_histogram.png"
    PNG_CONCORDANCE_HIST = "mapped_subread_concordance_histogram.png"
    PNG_READLENGTH = "mapped_readlength_histogram.png"
    PNG_RAINBOW = "mapped_concordance_vs_read_length.png"


def _to_bam_stats(bam_file, length_bin_width=25, ignore_negative=True):
    try:
        with IndexedBamReader(bam_file) as bam:
            movie_names = {rg.ID: rg.MovieName for rg in bam.readGroupTable}
            stats = collect_pbi_alignment_metrics(bam.pbi, movie_names, ignore_negative=ignore_negative)
            return stats, to_readlength_accuracy_histogram2d(bam.pbi.aEnd - bam.pbi.aStart, bam.identity, bin_sizes=(0.005, length_bin_width))
    except Exception as exc:
        extra_msg = ': Error in Bam file "{}"'.format(bam_file)
        reraise(type(exc), type(exc)(str(exc) + extra_msg), sys.exc_info()[2])


def __to_bam_stats(args):
    bam_file, length_bin_width, ignore_negative = args
    return _to_bam_stats(bam_file, length_bin_width, ignore_negative)


def get_all_bam_stats(bam_files, nproc, length_bin_width=25, ignore_negative=True):
    """
    Collect read statistics objects in parallel from the list of indexed BAM
    files.
    """
    log.info("Collecting metrics from %d bam.pbi files", len(bam_files))
    args = [(f, length_bin_width, ignore_negative) for f in bam_files]
    result = pool_map(__to_bam_stats, args, nproc)
    stats = [r[0] for r in result]
    combined, by_movie = combine_chunked_alignment_metrics(stats)
    plot_data = combine_histogram2d([r[1] for r in result])
    return combined, by_movie, plot_data


def _to_attributes(aln_info):
    attr = []
    for id_, value in [
            (Constants.A_SUBREAD_CONCORDANCE, aln_info.info.mean_identity),
            (Constants.A_SUBREAD_NBASES, aln_info.subreads.nbases),
            (Constants.A_NSUBREADS, aln_info.subreads.size),
            (Constants.A_NALIGNMENTS, aln_info.info.n_alignments),
            (Constants.A_SUBREAD_LENGTH, aln_info.subreads.mean),
            (Constants.A_SUBREAD_LENGTH_N50, aln_info.subreads.n50),
            (Constants.A_SUBREAD_LENGTH_Q95, aln_info.subreads.q95),
            (Constants.A_SUBREAD_LENGTH_MAX, aln_info.subreads.max),
            (Constants.A_NREADS, aln_info.reads.size),
            (Constants.A_READLENGTH, aln_info.reads.mean),
            (Constants.A_READLENGTH_N50, aln_info.reads.n50),
            (Constants.A_READLENGTH_Q95, aln_info.reads.q95),
            (Constants.A_READLENGTH_MAX, aln_info.reads.max)]:
        log.info("%s = %g", id_, value)
        attr.append(Attribute(id_, value=value))
    return attr


def _to_table_row(aln_info):
    name = aln_info.movie_name if aln_info.movie_name else "All Movies"
    return [
        (Constants.C_MOVIE, name),
        (Constants.C_READS, aln_info.reads.size),
        (Constants.C_READLENGTH, aln_info.reads.mean),
        (Constants.C_READLENGTH_N50, aln_info.reads.n50),
        (Constants.C_SUBREADS, aln_info.subreads.size),
        (Constants.C_SUBREAD_NBASES, aln_info.subreads.nbases),
        (Constants.C_SUBREAD_LENGTH, aln_info.subreads.mean),
        (Constants.C_SUBREAD_CONCORDANCE, aln_info.info.mean_identity)
    ]


def to_read_metrics_table(to_row, combined, by_movie):
    """
    Plot a table of a subset of the metrics from the Attributes section,
    with rows for each movie individually (as well as the overall stats).
    """
    table = Table(Constants.T_STATS)
    rows = [to_row(combined)]
    if len(by_movie) == 1:  # hacky optimization
        movie_row = [list(field) for field in rows[0]]
        movie_row[0][1] = by_movie.keys()[0]
        rows.append(movie_row)
    else:
        for movie_name in sorted(by_movie.keys()):
            rows.append(to_row(by_movie[movie_name]))
    for i_col, (col_id, _) in enumerate(rows[0]):
        col = Column(col_id, values=[row[i_col][1] for row in rows])
        table.add_column(col)
    return table


_to_subread_metrics_table = functools.partial(
    to_read_metrics_table, _to_table_row)


def _to_tables(combined, by_movie):
    return [_to_subread_metrics_table(combined, by_movie)]


def _to_histogram_plotgroup(use_spec, plotgroup_id, plot_id, read_type, bincounts, output_dir, png_name):
    """
    Create a histogram of length distribution.
    """
    plot_spec = use_spec.get_plot_spec(plotgroup_id, plot_id)
    png_file = op.join(output_dir, png_name)
    png, thumb = plot_read_lengths_binned(bincounts,
                                          png_file,
                                          read_type=read_type,
                                          title=plot_spec.title,
                                          color=get_blue(3),
                                          edgecolor=get_blue(2))
    return to_plotgroup(plotgroup_id, plot_id, png, thumb)


def to_read_length_histogram(constants, metrics, output_dir):
    return _to_histogram_plotgroup(constants.SPEC,
                                   constants.PG_READLENGTH,
                                   constants.P_READLENGTH,
                                   "Read",
                                   metrics.info.read_bins,
                                   output_dir,
                                   constants.PNG_READLENGTH)


_to_read_length_histogram = functools.partial(
    to_read_length_histogram, Constants)


def _to_subread_length_histogram(metrics, output_dir):
    return _to_histogram_plotgroup(Constants.SPEC,
                                   Constants.PG_SUBREAD_LENGTH,
                                   Constants.P_SUBREAD_LENGTH,
                                   "Alignment",
                                   metrics.info.subread_bins,
                                   output_dir,
                                   Constants.PNG_SUBREAD_LENGTH)


def to_concordance_histogram(constants, metrics, output_dir):
    png_file_name = op.join(output_dir, constants.PNG_CONCORDANCE_HIST)
    plot_x, plot_y = metrics.info.get_subread_concordance_histogram()
    plot_spec = constants.SPEC.get_plot_spec(constants.PG_CONCORDANCE_HIST,
                                             constants.P_CONCORDANCE_HIST)
    png, thumb = plot_concordance_histogram(plot_x,
                                            plot_y,
                                            png_file_name,
                                            plot_spec.xlabel,
                                            plot_spec.ylabel)
    return to_plotgroup(constants.PG_CONCORDANCE_HIST,
                        constants.P_CONCORDANCE_HIST,
                        png, thumb)


_to_subread_concordance_histogram = functools.partial(
    to_concordance_histogram, Constants)


def _to_length_vs_concordance_plot(plot_data, output_dir, metrics):
    png_file_name = op.join(output_dir, Constants.PNG_RAINBOW)
    plot_spec = spec.get_plot_spec(Constants.PG_RAINBOW, Constants.P_RAINBOW)
    max_length = metrics.subreads.mean + 100 * metrics.subreads.stddev
    png, thumb = plot_mapped_concordance_vs_read_length_hist2d(
        plot_data.crop(x_limits=(0, max_length)),
        png_file_name,
        x_label=plot_spec.xlabel,
        log_scale=True)
    return to_plotgroup(Constants.PG_RAINBOW, Constants.P_RAINBOW, png, thumb)


def _to_plotgroups(metrics, output_dir, histogram):
    return [
        _to_read_length_histogram(metrics, output_dir),
        _to_subread_length_histogram(metrics, output_dir),
        _to_subread_concordance_histogram(metrics, output_dir),
        _to_length_vs_concordance_plot(histogram, output_dir, metrics)
    ]


def _to_yield_attribute(subreads_in, metrics):
    with SubreadSet(subreads_in) as subreads:
        subreads.updateCounts()
        n_bases_raw = subreads.totalLength
        n_bases_mapped = metrics.subreads.nbases
        pct_bases_mapped = 0.0
        if n_bases_raw > 0:
            pct_bases_mapped = float(n_bases_mapped) / n_bases_raw
        return subreads.uuid, Attribute(Constants.A_PCT_MAPPED,
                                        value=pct_bases_mapped)


def make_report(bam_files, output_dir, nproc=1, dataset_uuids=(),
                subreads_in=None,
                report_id=Constants.R_ID,
                length_bin_width=25,
                ignore_negative=True):
    """
    Collect data from BAM indices and populate Report object.
    """
    combined, by_movie, histogram = get_all_bam_stats(
        bam_files, nproc, length_bin_width, ignore_negative=ignore_negative)
    plotgroups = []
    if combined.info.n_reads > 0:
        plotgroups = _to_plotgroups(combined, output_dir, histogram)
    attributes = []
    if subreads_in is not None:
        subreads_uuid, attr = _to_yield_attribute(subreads_in, combined)
        dataset_uuids = list(dataset_uuids) + [subreads_uuid]
        attributes.append(attr)
    attributes.extend(_to_attributes(combined))
    return Report(
        report_id,
        attributes=attributes,
        tables=_to_tables(combined, by_movie),
        plotgroups=plotgroups,
        dataset_uuids=dataset_uuids)


def to_report(alignment_file,
              report_json,
              nproc=1,
              use_spec=spec,
              subreads_in=None,
              report_id=Constants.R_ID,
              ignore_negative=True):
    """
    Main entry function including I/O.
    """
    output_dir = op.dirname(report_json)
    bam_files = []
    log.info("Opening %s as an AlignmentSet", alignment_file)
    length_bin_width = 25
    with openDataFile(alignment_file, strict=True, skipCounts=True) as ds:
        length_bin_width = get_best_length_binning(
            ds.totalLength, ds.numRecords)
        for bam_resource in ds.externalResources:
            if bam_resource.pbi is None:
                raise ValueError(
                    "This program requires PacBio-indexed (.pbi) BAM files")
            bam_files.append(bam_resource.bam)
        rpt = use_spec.apply_view(make_report(
            bam_files, output_dir, nproc, [ds.uuid],
            subreads_in=subreads_in, report_id=report_id,
            length_bin_width=length_bin_width,
            ignore_negative=ignore_negative))
        rpt.write_json(report_json)
        log.info("Wrote report to %s", report_json)
    return 0


def get_parser(c=Constants):  # pragma: no cover
    parser = get_pbparser(c.TOOL_ID,
                          c.VERSION,
                          "Mapping Statistics",
                          c.DOC,
                          c.DRIVER_EXE,
                          nproc=c.MAX_NPROC)
    parser.add_input_file_type(c.MAPPED_FILE_TYPE, "alignment_file",
                               "Alignment XML DataSet",
                               "BAM, SAM or Alignment DataSet")
    parser.add_output_file_type(FileTypes.REPORT, "report_json",
                                "Mapping Statistics Report",
                                "Summary of alignment results", c.R_ID)
    parser.arg_parser.parser.add_argument("--unmapped", dest="subreads_file", action="store", default=None, help="Unmapped BAM or SubreadSet")
    parser.arg_parser.parser.add_argument("--nproc", action="store", type=int, default=1,
                                          help="Number of processors for reading .pbi files.  Not recommended to be more than 8 due to IO overhead.")
    return parser


def args_runner(args):  # pragma: no cover
    return to_report(args.alignment_file, os.path.abspath(args.report_json),
                     args.nproc)


def rtc_runner(rtc):
    return to_report(rtc.task.input_files[0], rtc.task.output_files[0],
                     nproc=rtc.task.nproc)


def main(argv=sys.argv):  # pragma: no cover
    return pbparser_runner(argv[1:],
                           get_parser(),
                           args_runner,
                           rtc_runner,
                           log,
                           setup_log)


if __name__ == '__main__':
    sys.exit(main())
