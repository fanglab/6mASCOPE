
"""
New CCS report, for running on dataset import or generation in new auto-CCS
pipeline (including demultiplexed datasets)
"""

from collections import namedtuple
import tempfile
import zipfile
import os.path as op
import os
import sys
import logging
from pprint import pformat

import numpy as np

from pbcommand.models.report import Report, Table, Column, Attribute
from pbcommand.models import FileTypes, get_pbparser
from pbcommand.cli import pbparser_runner
from pbcommand.utils import setup_log
from pbcore.io import ConsensusReadSet
from pbcore.util.statistics import accuracy_as_phred_qv

from pbreports.plot.tools import (
    plot_q20_read_length_distribution, plot_read_scores)
from pbreports.plot.helper import to_plotgroup
from pbreports.io.specs import load_spec

log = logging.getLogger(__name__)
__version__ = '0.4.1'


class Constants(object):
    TOOL_ID = "pbreports.tasks.ccs2_report"
    TOOL_NAME = "ccs2_report"
    DRIVER_EXE = "python -m pbreports.report.ccs2 --resolved-tool-contract"

    CSV_FILE_NAME = "ccs_statistics.csv"

    R_ID = "ccs2"

    # PlotGroup
    PG_READLENGTH = 'readlength_group'
    PG_ACCURACY = "accuracy_group"

    # Plots
    P_READLENGTH = "readlength_hist"
    P_ACCURACY = "accuracy_hist"

    PNG_READLENGTH = "ccs_readlength_hist.png"
    PNG_ACCURACY = "ccs_accuracy_hist.png"

    # Attributes
    A_NREADS = 'number_of_ccs_reads'
    A_TOTAL_BASES = 'total_number_of_ccs_bases'
    A_MEAN_READLENGTH = 'mean_ccs_readlength'
    A_MEDIAN_ACCURACY = 'median_accuracy'
    A_NREADS_LQ = "n_low_quality_reads"
    A_TOTAL_BASES_LQ = "total_number_of_ccs_bases_lq"
    A_MEAN_READLENGTH_LQ = "mean_ccs_readlength_lq"
    A_MEDIAN_ACCURACY_LQ = "median_accuracy_lq"

    # Table
    T_ID = 'ccs_table'

    # Columns
    C_MOVIE_NAME = 'movie_name'
    C_NREADS = "number_of_ccs_reads"
    C_TOTAL_BASES = 'total_number_of_ccs_bases'
    C_MEAN_READLENGTH = 'ave_ccs_readlength'


# when run as part of demultiplexing, we need a different report ID
class ConstantsDemultiplexed(Constants):
    R_ID = "ccs_demux_stats"


def _get_index(ccs_set, use_pbi_only=False):
    MockPbi = namedtuple("MockPbi", ["qId", "holeNumber", "qEnd", "readQual"])
    if np.any(ccs_set.index.qEnd == -1):  # old .pbi file
        if use_pbi_only:
            raise IOError("Old .pbi found, aborting")
        else:
            log.warn("Old .pbi file found, falling back on BAM file")
            return MockPbi(
                ccs_set.index.qId,
                ccs_set.index.holeNumber,
                np.fromiter((rec.qLen for rec in ccs_set), dtype=int),
                ccs_set.index.readQual)
    else:
        return ccs_set.index


def _get_stats_by_movie(ccs_set, index):
    MovieResult = namedtuple("MovieResult", ["movie_name", "read_lengths",
                                             "accuracies"])
    for rg in ccs_set.readGroupTable:
        rg_id = rg["ID"]
        index_sel = index.qId == rg_id
        yield MovieResult(rg["MovieName"],
                          index.qEnd[index_sel],
                          index.readQual[index_sel])


def __get_metrics(read_lengths, accuracies, selection):
    rl_sel = read_lengths[selection]
    nreads = rl_sel.size
    nbases = int(np.sum(rl_sel))
    acc_sel = sorted(accuracies[selection])
    median_accuracy = float(acc_sel[nreads / 2]) if nreads > 0 else 0
    mean_readlength = int(rl_sel.mean()) if nreads > 0 else 0
    accuracy_str = "Q" + str(int(accuracy_as_phred_qv(median_accuracy)))
    return nreads, nbases, accuracy_str, mean_readlength


def _to_core_metrics(read_lengths, accuracies):
    Metrics = namedtuple(
        "Metrics", ["nreads", "nbases", "read_length", "accuracy", "nreads_lq", "nbases_lq", "read_length_lq", "accuracy_lq"])
    q20_sel = accuracies >= 0.99
    nreads, nbases, median_accuracy, mean_readlength = __get_metrics(read_lengths, accuracies, q20_sel)
    # low-quality read metrics
    lq_sel = np.invert(q20_sel)
    nreads_lq, nbases_lq, accuracy_lq, mean_readlength_lq = __get_metrics(read_lengths, accuracies, lq_sel)
    return Metrics(nreads, nbases, mean_readlength, median_accuracy, nreads_lq, nbases_lq, mean_readlength_lq, accuracy_lq)


def _to_attributes(index):
    """Create the necessary attributes for the CCS report"""
    m = _to_core_metrics(index.qEnd, index.readQual)
    attr = [
        Attribute(Constants.A_NREADS, value=m.nreads),
        Attribute(Constants.A_TOTAL_BASES, value=m.nbases),
        Attribute(Constants.A_MEAN_READLENGTH, value=m.read_length),
        Attribute(Constants.A_MEDIAN_ACCURACY, value=m.accuracy)
    ]
    if m.nreads_lq > 0:
        attr.extend([
            Attribute(Constants.A_NREADS_LQ, value=m.nreads_lq),
            Attribute(Constants.A_TOTAL_BASES_LQ, value=m.nbases_lq),
            Attribute(Constants.A_MEAN_READLENGTH_LQ, value=m.read_length_lq),
            Attribute(Constants.A_MEDIAN_ACCURACY_LQ, value=m.accuracy_lq)
        ])
    return attr


def _to_table_by_movie(ccs_set, index):
    """
    Group movie results by movie name and build a report table.

    Table has movie name, # of CCS bases, Total CCS bases,
    mean CCS readlength and mean CCS accuracy.
    """

    columns = []
    columns.append(Column(Constants.C_MOVIE_NAME, values=[]))
    columns.append(Column(Constants.C_NREADS, values=[]))
    columns.append(Column(Constants.C_TOTAL_BASES, values=[]))
    columns.append(Column(Constants.C_MEAN_READLENGTH, values=[]))
    table = Table(Constants.T_ID, columns=columns)

    movies = list(_get_stats_by_movie(ccs_set, index))
    movies.sort(lambda a, b: cmp(a.movie_name, b.movie_name))
    for movie in movies:
        stats = _to_core_metrics(movie.read_lengths, movie.accuracies)
        table.add_data_by_column_id(Constants.C_MOVIE_NAME, movie.movie_name)
        table.add_data_by_column_id(Constants.C_NREADS, stats.nreads)
        table.add_data_by_column_id(Constants.C_TOTAL_BASES, stats.nbases)
        table.add_data_by_column_id(
            Constants.C_MEAN_READLENGTH, stats.read_length)
    if len(movies) > 1:
        stats = _to_core_metrics(index.qEnd, index.readQual)
        table.add_data_by_column_id(Constants.C_MOVIE_NAME, "Total")
        table.add_data_by_column_id(Constants.C_NREADS, stats.nreads)
        table.add_data_by_column_id(Constants.C_TOTAL_BASES, stats.nbases)
        table.add_data_by_column_id(
            Constants.C_MEAN_READLENGTH, stats.read_length)

    return table


def _to_per_read_csv(ccs_set, index, csv_file):
    csv_tmp = tempfile.NamedTemporaryFile(suffix=".csv").name
    with open(csv_tmp, "wb") as csv_out:
        log.info("Generating per-read CSV report...")

        def writer(q, l, s):
            csv_out.write("\n{q},{l},{s:.3f}".format(l=l, q=q, s=s))
        csv_out.write("qname,qlen,readscore")
        movies = {rg["ID"]: rg["MovieName"] for rg in ccs_set.readGroupTable}
        for qId, holeNumber, qLen, readQual in zip(index.qId,
                                                   index.holeNumber,
                                                   index.qEnd,
                                                   index.readQual):
            qname = "{m}/{z}/ccs".format(m=movies[qId], z=holeNumber)
            writer(qname, qLen, readQual)
    log.info("Compressing CSV")
    with zipfile.ZipFile(csv_file, "w", zipfile.ZIP_DEFLATED,
                         allowZip64=True) as zip_out:
        zip_out.write(csv_tmp, Constants.CSV_FILE_NAME)
    os.remove(csv_tmp)


def _to_read_length_plot(read_lengths, read_scores, base_dir):
    png_file_name = op.join(base_dir, Constants.PNG_READLENGTH)
    _, thumbnail = plot_q20_read_length_distribution(
        read_lengths,
        read_scores,
        png_file_name)
    return to_plotgroup(Constants.PG_READLENGTH,
                        Constants.P_READLENGTH,
                        png_file_name,
                        thumbnail)


def _to_accuracy_plot(read_scores, base_dir):
    png_file_name = op.join(base_dir, Constants.PNG_ACCURACY)
    _, thumbnail = plot_read_scores(
        read_scores,
        png_file_name,
        cutoff_line=20)
    return to_plotgroup(Constants.PG_ACCURACY,
                        Constants.P_ACCURACY,
                        png_file_name,
                        thumbnail)


def _to_plot_groups(index, base_dir):
    if len(index) == 0:
        return []
    qv_scores = accuracy_as_phred_qv(index.readQual)
    plot_groups = [
        _to_read_length_plot(index.qEnd, qv_scores, base_dir)
    ]
    is_all_zero_quality = (index.readQual == 0.0).all()
    if not is_all_zero_quality:
        log.info("Non-zero read qualities, will generate accuracy plot")
        plot_groups.append(_to_accuracy_plot(qv_scores, base_dir))
    else:
        log.info("All read qualities are 0 - skipping accuracy plot")
    return plot_groups


def _is_multi_barcode_dataset(ccs_set):
    fw, rev = ccs_set.index.bcForward, ccs_set.index.bcForward
    if len(fw) > 0:
        return not (np.all(fw == fw[0]) and np.all(rev == rev[0]))
    return False


def make_report(ccs_set, output_dir, csv_file=None, constants=Constants):
    index = _get_index(ccs_set)
    if csv_file is not None:
        log.info("Writing per-read metrics to %s", csv_file)
        _to_per_read_csv(ccs_set, index, csv_file)

    if ccs_set.isBarcoded:
        if _is_multi_barcode_dataset(ccs_set):
            log.warn("Incomplete support for multi-barcode datasets")
        else:
            log.info("This is a single-barcode (demultiplexed) dataset")

    spec = load_spec(constants.R_ID)
    tables = []
    if len(ccs_set.readGroupTable) > 1:
        tables.append(_to_table_by_movie(ccs_set, index))
    report = Report(constants.R_ID,
                    title=spec.title,
                    tables=tables,
                    attributes=_to_attributes(index),
                    plotgroups=_to_plot_groups(index, output_dir),
                    dataset_uuids=(ccs_set.uuid,))

    return spec.apply_view(report)


def run_report(
        input_file,
        report_json,
        report_csv,
        output_dir):
    log.info("Running {f} v{v}.".format(
        f=op.basename(__file__), v=__version__))
    report = None
    ds = ConsensusReadSet(input_file)
    report = make_report(ds, output_dir, report_csv)
    log.info(pformat(report.to_dict()))
    report.write_json(report_json)
    return 0


def _args_runner(args):
    return run_report(
        input_file=args.ccs_in,
        report_json=args.report_json,
        report_csv=args.csv_out,
        output_dir=op.dirname(op.abspath(args.report_json)))


def _resolved_tool_contract_runner(rtc):
    return run_report(
        input_file=rtc.task.input_files[0],
        report_json=rtc.task.output_files[0],
        report_csv=rtc.task.output_files[1],
        output_dir=op.dirname(rtc.task.output_files[0]))


def _get_parser():
    p = get_pbparser(
        tool_id=Constants.TOOL_ID,
        version=__version__,
        name=Constants.TOOL_NAME,
        description=__doc__,
        driver_exe=Constants.DRIVER_EXE)
    ap = p.arg_parser.parser
    tcp = p.tool_contract_parser
    p.add_input_file_type(FileTypes.DS_CCS, "ccs_in",
                          name="ConsensusReadSet",
                          description="ConsensusRead DataSet file")
    p.add_output_file_type(FileTypes.REPORT, "report_json",
                           name="CCS Report",
                           description="Summary of results from CCS2",
                           default_name="ccs_report")
    tcp.add_output_file_type(FileTypes.ZIP, "csv_out",
                             name="CCS Statistics",
                             description="Listing of essential metrics for individual CCS reads in CSV format (compressed)",
                             default_name=Constants.CSV_FILE_NAME)
    ap.add_argument('-c', "--csv-out", dest="csv_out", default=None,
                    help="Optional csv.zip file with per-read info")
    return p


def main(argv=sys.argv):  # pragma: no-cover
    """Main point of Entry"""
    return pbparser_runner(
        argv=argv[1:],
        parser=_get_parser(),
        args_runner_func=_args_runner,
        contract_runner_func=_resolved_tool_contract_runner,
        alog=log,
        setup_log_func=setup_log)


if __name__ == "__main__":
    sys.exit(main())
