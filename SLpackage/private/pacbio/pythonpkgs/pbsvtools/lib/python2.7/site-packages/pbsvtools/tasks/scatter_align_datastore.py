#! python

"""
Split input alignment datastore into at most max_nchunk chunks.
"""
from __future__ import absolute_import

import logging
import sys
import math
import os.path as op

from pbcommand.cli import (pacbio_args_runner,
                           get_default_argparser_with_base_opts)
from pbcommand.utils import setup_log
from pbcommand.models import FileTypes

from pbcoretools.datastore_utils import dataset_to_datastore, datastore_to_datastorefile_objs
from pbsvtools.tasks.scatter_align_json_to_svsig import datastore_to_bam_files
from .scatter_call import put_items_to_boxes

log = logging.getLogger(__name__)
__version__ = "0.1.0"


def scatter_align_json(i_datastore_fn, output_dir, max_nchunks):
    """
    Parameters:
      i_datastore_fn --- DataStore json of AlignmentSet or ConsensusAlignmentSet to chunk.
      output_dir --- Output directory.
      max_nchunks --- Split input datastore into at most max_nchunks chunks.
    """
    output_dir = op.abspath(op.expanduser(output_dir))

    basename = 'chunk'
    ALLOWED_TYPES = (FileTypes.DS_ALIGN, FileTypes.DS_ALIGN_CCS)

    # Chunk input datastore json, generate multiple chunked datastore.json, and
    # generate pbcommand.models.PipelineChunk objects
    _, _, readcls, ext = datastore_to_datastorefile_objs(
            i_datastore_fn, allowed_types=ALLOWED_TYPES)
    bam_fns = datastore_to_bam_files(i_datastore_fn)

    # Put bam files into boxes
    n_chunks = max(1, min(max_nchunks, len(bam_fns)))
    cutoff = math.ceil(len(bam_fns)*1.0/n_chunks)
    boxes = put_items_to_boxes(bam_fns, [1 for _ in range(len(bam_fns))], n_chunks, cutoff)

    for i, bam_fns_in_box in enumerate(boxes):
        # WARNING: if output json filename is changed, must update
        # chunk name to collect in sv.wdl.
        out_xml = op.join(output_dir, '{}.{}.{}'.format(basename, i, ext))
        out_json = op.join(output_dir, '{}.{}.{}'.format(basename, i, 'datastore.json'))
        readcls(*bam_fns_in_box).write(out_xml)
        dataset_to_datastore(out_xml, out_json, "scatter_align_datastore")
    return 0


def run_args(args):
    scatter_align_json(i_datastore_fn=args.i_datastore_fn,
                       output_dir=args.output_dir,
                       max_nchunks=args.max_nchunks)


def _get_parser():
    p = get_default_argparser_with_base_opts(
        version=__version__,
        description=__doc__,
        default_level="INFO")
    p.add_argument("i_datastore_fn", type=str, help="Input alignment.datastore.json generated by pbmm2")
    p.add_argument("output_dir", type=str, help="Output directory")
    p.add_argument("max_nchunks", type=int, help="Split input into at most max_nchunks chunks.")
    return p


def main(argv=sys.argv):
    return pacbio_args_runner(
        argv=argv[1:],
        parser=_get_parser(),
        args_runner_func=run_args,
        alog=log,
        setup_log_func=setup_log)


if __name__ == "__main__":
    sys.exit(main(sys.argv))
