"""Call structural variants"""
from __future__ import absolute_import
from __future__ import division

import random
import logging
import collections
import heapq

from .libs import Fastafile
from .io.VcfIO import BedRecord, BedWriter, VcfRecord, VcfWriter, to_pbsv_id
from .io.bamstream import (AnnotateSampleBamStream, get_samples_from_header, json_to_fns_and_samples,
    is_good_mapped_alignment, yield_sampled_aln)
from .inversion import is_inv_aln
from .aln import cigar
from .independent.utils import is_bed, is_vcf, is_json, revcomp
from .utils import get_fa_from_referenceset_or_fa, get_seq_from_pysam_fastafile, get_sample_from_alignedseg
from .independent.common import (SvType, SvFmt, ReadSvWindowCluster, ReadSvWindow, SvFmts,
        readcount_depth_percent_to_gt)
from .annot import annot_seq
from .set_readgroup import get_sm_tag_from_alignedseg

from . import Constants as C


log = logging.getLogger()


#__all__ = ["svcall"] functions that matters the most.


def cigarupdatecoords(op, oplen, q0, r0):
    """Apply a CIGAR operation to update query and reference coordinates.

    `op` is the CIGAR operation
    `oplen` is the length of the CIGAR operation
    `q0` is the query coordinate before the CIGAR operation
    `r0` is the reference coordinate before the CIGAR operation

    return `q1,r1` the query/ref coordinates after the CIGAR operation
    """
    q1 = q0 + (oplen if op in cigar.QUERYOPS else 0)
    r1 = r0 + (oplen if op in cigar.REFOPS else 0)
    return q1, r1


def repr_aln(s):
    """Return a string which briefly represents a mapped alignedseg obj.
    """
    assert s.reference_id != -1, 'AlignSeg of {} is not mapped.'.format(s.query_name)
    return '(%s, %s, %s, %s)' % (s.query_name, s.reference_id, s.reference_name, s.reference_start)


def findinvwindows(s, reffa, svlength):
    """Convert an inversion alignment to an inversion SV window, and yield the window. """
    if not is_inv_aln(s) or s.query_alignment_length < svlength:
        raise StopIteration
    qseq = s.query_sequence.upper()
    rseq = reffa.fetch(s.reference_name, s.reference_start, s.reference_end).upper()
    svs = ReadSvWindow(s, s.query_name, s.query_alignment_start, s.query_alignment_end, qseq,
                       s.reference_name, s.reference_start, s.reference_end,
                       rseq, 0, SvType.Inversion, s.query_alignment_length)
    yield svs


def findexcesswindows(s, reffa, posops, negops, sizeops,
                      maxsize, minexcess, svtype,
                      gapdistance, margin):
    """Find alignment windows (i.e. CIGAR substrings) that contain an excess of
    "positive" CIGAR operations (`posops`) over "negative" operations (`negops`).

    Return all optimal windows with a maximum size of `maxsize` that have an
    excess of at least `minexcess`.  An optimal window is one for which no
    superwindow (i.e. containing window) has a higher excess and no subwindow
    (i.e. contained window) has an equivalent or higher excess.  Window size
    is measured as the summed lengths of "size" operations (`sizeops`).
    """

    scigars = collections.deque(s.cigartuples)
    qstart = 0                 # "query" start relative to the the full read
    rstart = s.reference_start  # "reference" start relative to chromosome
    qoffset, roffset = 0, max(rstart - gapdistance, 0)
    qseq = s.query_sequence.upper()
    rseq = reffa.fetch(s.reference_name, max(s.reference_start - gapdistance, 0), s.reference_end + gapdistance).upper()

    # Process and remove clipping CIGAR operations.
    while scigars[0][0] in cigar.CLIPPINGOPS:  # process and remove left clipping
        qstart += scigars[0][1]  # left clipping advances the qstart
        qoffset += scigars[0][1] if scigars[0][0] == cigar.HARD_CLIP else 0
        scigars.popleft()
    while scigars[-1][0] in cigar.CLIPPINGOPS:  # remove right clipping
        scigars.pop()

    result = list()  # optimal windows to return

    # Slide a window along the CIGAR string.
    wcigars = collections.deque()  # CIGAR operations in the candidate window
    # summed lengths of `sizeops`, `posops`, and `negops` in the candidate
    # window
    wsize, wpos, wneg = 0, 0, 0
    # query and reference start coordinates for the window
    wqstart, wrstart = qstart, rstart

    # Iterate until both `scigars` and `wcigars` are exhausted.  In each iteration
    # `scigarlen` or `wcigarlen` is reduced.
    scigarlen, wcigarlen = len(scigars), len(wcigars)
    while (scigarlen + wcigarlen) > 0:
        # 1) Extend the window if it does not yet exceed its maximum size.
        if scigarlen > 0 and wsize <= maxsize:
            # Move the operation at the front of `scigars` to the window.
            op, oplen = scigars.popleft()
            wcigars.append((op, oplen))
            scigarlen -= 1
            wcigarlen += 1

            # Update window properties.
            wsize = wsize + (oplen if op in sizeops else 0)
            wpos = wpos + (oplen if op in posops else 0)
            wneg = wneg + (oplen if op in negops else 0)

        # 2) Find the window that starts at the front of `wcigars` with the greatest excess of `posops` over `negops`.
        #    Then, advance the front of `wcigars`.
        else:
            # If the front of `wcigars` is not a "positive" operation, then it is not the start of
            # an optimal subwindow, as a window that starts at the subsequent operation is shorter
            # and has at least as great an excess.
            if wcigars[0][0] in posops:
                # Find the window that starts at the front of `wcigars` with the highest excess.
                # Prefer shorter windows among those with equivalent excess.
                swmaxexcess, swpos, swneg = 0, 0, 0
                swmaxqend, swmaxrend = wqstart, wrstart
                swqend, swrend = wqstart, wrstart
                for op, oplen in wcigars:
                    # The highest possible excess from extending the window is `wpos - swneg`.
                    # Short circuit if that is not high enough to satisfy
                    # `minexcess`.
                    if wpos - swneg < minexcess:
                        break

                    # Extend the scanning window with (op, oplen)
                    swpos = swpos + (oplen if op in posops else 0)
                    swneg = swneg + (oplen if op in negops else 0)
                    swqend, swrend = cigarupdatecoords(
                        op, oplen, swqend, swrend)
                    if (swpos - swneg) > swmaxexcess:
                        swmaxexcess = swpos - swneg
                        swmaxqend, swmaxrend = swqend, swrend

                if swmaxexcess >= minexcess:
                    svs = ReadSvWindow(s, s.query_name, wqstart, swmaxqend, qseq[wqstart - qoffset:swmaxqend - qoffset],
                                       s.reference_name, wrstart, swmaxrend, rseq[wrstart - roffset:swmaxrend - roffset], 0, svtype, swmaxexcess)
                    if len(result) == 0:  # new window is the first one output
                        result.append(svs)
                    else:  # compare to the previous window
                        wprev = result[-1]

                        # not a subwindow of `wprev`
                        if (wprev.readEnd < swmaxqend) or (wprev.refEnd < swmaxrend):
                            result.append(svs)
                        elif wprev.svLen <= swmaxexcess:  # subwindow of `wprev` with at least as high an excess
                            result.pop()  # remove `wprev`
                            result.append(svs)
                        # else `wprev` is a superwindow with a higher excess;
                        # prefer `wprev`

            # Advance the front of the window.
            op, oplen = wcigars.popleft()
            wcigarlen -= 1

            # Update window properties.
            wsize = wsize - (oplen if op in sizeops else 0)
            wpos = wpos - (oplen if op in posops else 0)
            wneg = wneg - (oplen if op in negops else 0)
            wqstart, wrstart = cigarupdatecoords(op, oplen, wqstart, wrstart)

    # Return excess windows.  Skip windows that are too close to a reference assembly
    # gap or to the end of the read alignment.
    gaps = []  # (chromStart,chromEnd) tuples
    curgapstart = -1
    for ix, base in enumerate(rseq):
        if base != "N" and curgapstart != -1:  # close any open gap
            gaps.append((curgapstart, ix + roffset))
            curgapstart = -1
        elif base == "N":  # extend or open a gap
            curgapstart = curgapstart if curgapstart != -1 else ix + roffset
    if curgapstart != -1:  # record the final gap
        gaps.append((curgapstart, s.reference_end))

    for x in result:
        # find distance to nearest gap
        gapDistance = gapdistance + 1
        for gapStart, gapEnd in gaps:
            if gapStart <= x.refStart:
                gapDistance = min(gapDistance, max(0, x.refStart - gapEnd))
            else:  # gapstart > x.refSstart
                gapDistance = min(gapDistance, max(0, gapStart - x.refEnd))
        # find distance (in reference basepairs) to end of the alignment
        alignmentEndDistance = min(
            x.refStart - s.reference_start, s.reference_end - x.refEnd)
        if gapDistance >= gapdistance and alignmentEndDistance >= margin:
            yield x


class StructuralVariant(object):
    """Class represents a structural variant object, including
    chromosome, chrom start position, chrom end position,
    structural variant type (Del/Ins), sv length,
    supportive reads, covering reads, inserted sequence if applicable
    """

    def __repr__(self):
        def to_s(reads):
            return ', '.join(['(%s, %s, %s, %s)' % (read.query_name, read.reference_name, read.reference_start, read.reference_end) if not isinstance(read, str) else read for read in reads])

        sr, cr = to_s(self.supportingReads), to_s(self.coveringReads)
        return 'StructuralVariant({}, {}, {}, {}, {}, {}, {}, {}, {})'.format(
                self.chrom, self.chromStart, self.chromEnd, self.svType, self.svLen, sr, cr, self.diffSequence, self.samples)

    def __init__(self, chrom, chromStart, chromEnd, svType, svLen, supportingReads, coveringReads, diffSequence, samples):
        self.chrom = chrom
        self.chromStart = chromStart
        self.chromEnd = chromEnd
        self.svType = svType
        self.svLen = svLen
        self.supportingReads = supportingReads
        self.coveringReads = coveringReads
        assert all([r.reference_name == chrom for r in supportingReads]), 'All supporting reads must all map to {!r}'.format(chrom)
        assert all([r.reference_name == chrom for r in coveringReads]), 'All covering reads must all map to {!r}'.format(chrom)

        self.diffSequence = diffSequence
        assert self.diffSequence is not None

        self.samples = samples # list of sample names
        self.supportingReads = collections.defaultdict(list) # map from sample to list of supporting reads
        self.coveringReads = collections.defaultdict(list)   # map from sample to list of covering reads
        for s in supportingReads:
            sample = get_sm_tag_from_alignedseg(s) # require all AlignedSegment to have sm tag.
            self.supportingReads[sample].append(s)
        for s in coveringReads:
            sample = get_sm_tag_from_alignedseg(s) # require all AlignedSegment to have sm tag.
            self.coveringReads[sample].append(s)

    def __lt__(self, other):
        """Order structural variants by chrom,chromStart,svType,svLen"""
        return (self.chrom, self.chromStart, self.svType, self.svLen) < (other.chrom, other.chromStart, other.svType, other.svLen)

    @property
    def readCount(self):
        """Number of supporting reads across all samples."""
        return sum([len(set([s.query_name for s in v])) for k,v in self.supportingReads.items()])

    @property
    def readDepth(self):
        """The number of reads that cover the structural variant across all samples (both supporting and non-supporting)."""
        return sum([len(set([s.query_name for s in v])) for k,v in self.coveringReads.items()])

    @property
    def readPercentage(self):
        """Fraction of supporting reads over coverage"""
        return self.readCount * 100.0 / self.readDepth

    def sampleReadCount(self, sample):
        """Number of supporting reads for a single sample."""
        return len(set([s.query_name for s in self.supportingReads[sample]]))

    def sampleReadDepth(self, sample):
        """The number of reads that cover the structural variant for a single sample (both supporting and non-supporting)."""
        return len(set([s.query_name for s in self.coveringReads[sample]]))

    def sampleReadPercentage(self, sample):
        """Fraction of supporting reads over coverage for a sample"""
        readCount = self.sampleReadCount(sample)
        readDepth = self.sampleReadDepth(sample)
        return 0.0 if readDepth == 0 else readCount * 100.0 / readDepth

    def gt(self, sample):
        """Genotype, homozygous 1/1, heterozyous 0/1"""
        # Assume the variant is valid and assign a simple genotype.
        readCount = self.sampleReadCount(sample)
        readDepth = self.sampleReadDepth(sample)
        readPercentage = self.sampleReadPercentage(sample)
        return readcount_depth_percent_to_gt(readCount, readDepth, readPercentage)

    @property
    def fmt(self):
        """Return {gt}:{ad}:{dp} e.x., '0/1:3:6'}"""
        return SvFmt(gt=self.gt, ad=self.readCount, dp=self.readDepth)

    @property
    def annotations(self):
        """Return sorted annotations"""
        return annot_seq(seq=self.diffSequence)

    def pass_filter_criteria(self, min_readcount, min_readpercentage):
        """Return True if pass filter criteria"""
        #     1. total number of supporting reads across all samples is >= min_readcount
        # AND 2. percent of supporting reads >= min_readpercentage in at least one sample
        maxSampleReadPercentage = max([self.sampleReadPercentage(sample) for sample in self.samples])
        return self.readCount >= min_readcount and maxSampleReadPercentage >= min_readpercentage

    @property
    def svLen_w_sign(self):
        """svLen of <DEL> SVs are negative, svLen of <INS> SVs are positive"""
        return -abs(int(self.svLen)) if SvType(self.svType).is_Deletion else abs(int(self.svLen))

    def to_bed(self):
        """To a BedRecord"""
        seq = '.' if self.svType == SvType.Deletion else self.diffSequence

        return BedRecord(chrom=self.chrom, start=self.chromStart, end=self.chromEnd, sv_id=None,
                         sv_type=SvType(self.svType), sv_len=self.svLen_w_sign, alt=seq,
                         fmts=self.fmts, annotations=self.annotations)

    @property
    def _type(self):
        return SvType(self.svType)

    @property
    def _vcf_pos(self):
        """Return vcf POS.
           POS position: The reference position, with the 1st base having position 1.
        """
        return max(0, self.chromStart - 1) + 1

    def _vcf_pos_base(self, reffa):
        """Return base at ref[self._vcf_pos-1]."""
        # This is self._vcf_pos-1 because VCF is 1-based while the FASTA files is 0-based
        return get_seq_from_pysam_fastafile(reffa, self.chrom, self._vcf_pos-1, self._vcf_pos).upper()

    def _vcf_ref_seq(self, reffa):
        """Return vcf reference sequence, including padding base.
        Must be upper case.
        For indels, the reference String must include the base before the event.
        POS denotes the coordinate of the base preceding the polymorphism.

        For inversions, the REF allel is the single reference base pair at the POS, where
        POS is the coordinate of the first invered basepair
        """
        pad = self._vcf_pos_base(reffa)
        # ref --> the first base proceeding deletion + deleted bases, alt --> <DEL>
        if self._type.is_Deletion:
            return pad + get_seq_from_pysam_fastafile(reffa, self.chrom, self._vcf_pos, self.chromEnd).upper()
        elif self._type.is_Insertion: # ref --> the first base proceeding the event, alt -> <INS>
            return pad
        elif self._type.is_Inversion: # ref --> the single reference base pair at the POS
            return pad
        else:
            raise ValueError("Could not get reference sequence for structural variant of type %r" % self._type)

    def _vcf_alt_seq(self, reffa):
        """Get vcf ALT sequence, including padding base.
        Must be upper case.
        For inversions, ALT allele is the symbolic <INV>
        """
        pad = self._vcf_pos_base(reffa)
        if self._type.is_Deletion:
            return pad
            #return None # a symbolic allele will be used
        elif self._type.is_Insertion: # return exact inserted sequence, upper case.
            return pad + self.diffSequence.upper()
        elif self._type.is_Inversion: # alt -> <INV>
            return None
        else:
            raise ValueError("Could not get allele sequence for structural variant of type %r" % self._type)

    @property
    def fmts(self):
        return SvFmts.fromDict({sample: SvFmt(gt=self.gt(sample), ad=self.sampleReadCount(sample), dp=self.sampleReadDepth(sample)) for sample in self.samples})

    def to_vcf(self, reffa):
        """To a VcfRecord"""
        return VcfRecord(chrom=self.chrom, pos=self._vcf_pos, ref=self._vcf_ref_seq(reffa),
                         alt=self._vcf_alt_seq(reffa), fmts=self.fmts, annotations=self.annotations,
                         end=self.chromEnd, sv_type=self._type, sv_len=self.svLen_w_sign)


def findSvWindowsInRead(s, reffa, wSizeMax, svLen, gapdistance, margin):
    """Identify windows in a single read that contain potential structural variants.
    Return the windows ordered by chrom,chromStart."""

    rsvwHeap = []  # heap of read SV windows ordered by chrom,chromStart

    if not is_inv_aln(s): # do not look for insertion and deletion events in inversion alignments
        # Add generators for insertion and deletion variants.
        try:
            delGen = findexcesswindows(s, reffa, (cigar.DEL,), (cigar.INS,),
                                       cigar.QUERYOPS, wSizeMax, svLen, SvType.Deletion, gapdistance, margin)
            heapq.heappush(rsvwHeap, (next(delGen), delGen))
        except StopIteration:
            pass
        try:
            insGen = findexcesswindows(s, reffa, (cigar.INS,), (cigar.DEL,),
                                       cigar.REFOPS, wSizeMax, svLen, SvType.Insertion, gapdistance, margin)
            heapq.heappush(rsvwHeap, (next(insGen), insGen))
        except StopIteration:
            pass
    else: # Add generators for inversion
        try:
            invGen = findinvwindows(s, reffa, svLen)
            heapq.heappush(rsvwHeap, (next(invGen), invGen))
        except StopIteration:
            pass

    # Return the read SV windows
    while len(rsvwHeap):
        rsvw, rsvwGen = heapq.heappop(rsvwHeap)
        try:
            heapq.heappush(rsvwHeap, (next(rsvwGen), rsvwGen))
        except StopIteration:
            pass
        yield rsvw


def findSvWindowsInBam(bam, reffa, wSizeMax, svLen, mapq, secondary, duplicate, qcfail, margin, gapdistance):
    """Identify windows in any read in a BAM that contain potential structural variants.
    Return the windows ordered by chrom,chromStart."""

    rsvwHeap = []  # heap of read SV windows ordered by chrom,chromStart
    # heap of read end coordinates ordered by chrom,chromEnd (tuples of
    # chrom,chromEnd,chromStart,read)
    readHeap = []
    spre = None
    for idx, scur in enumerate(bam):
        # Assert alignments are filtered by mapping quality and alignment flags or is inversion, see is_good_aln
        is_good = not ((scur.mapping_quality < mapq) or (scur.is_secondary and not secondary) or
                       (scur.is_duplicate and not duplicate) or (scur.is_qcfail and not qcfail)) or \
                  is_inv_aln(scur)
        assert is_good, "Abort! Bad alignment %s" % scur

        # Sanity check alignments are sorted by genomic coordinates
        is_sorted =  (spre is None or spre.reference_name != scur.reference_name or
                spre.reference_start <= scur.reference_start)
        assert is_sorted, "Abort! alignments are not sorted! previous aln %s, current %s" % (repr_aln(spre), repr_aln(scur))
        spre = scur

        # Flush any read SV windows that start before `s`.
        while len(rsvwHeap) and (rsvwHeap[0][0].read.reference_id < scur.reference_id or rsvwHeap[0][0].refStart < scur.reference_start):
            # Find the next SV window to output.
            rsvw, rsvwGen = heapq.heappop(rsvwHeap)
            # Find the reads that cover the window plus some margin to the left and right.
            # The margin ensures that the read has enough sequence on both ends to unambiguously
            # support or refute a variant.  This is an unsophisticated way to measure unambiguous
            # support; a proper method would account for tandem repeats and require that the
            # read map to an unambiguous region on both ends.
            # For inversions, flanking ends are not necessary for covering reads.
            coveringReads = set()
            for dummy_chrom, chromEnd, chromStart, dummy_idx, read in readHeap:
                if (chromEnd >= rsvw.refEnd + margin and chromStart <= rsvw.refStart - margin) or \
                    (rsvw.svType == SvType.Inversion and chromEnd >= rsvw.refEnd and chromStart <= rsvw.refStart):
                    coveringReads.add(read)
            rsvw.coveringReads = coveringReads
            try:
                # add the next read SV window from the generator
                heapq.heappush(rsvwHeap, (next(rsvwGen), rsvwGen))
            except StopIteration:
                pass
            yield rsvw
        # Flush any reads that end before the start of `s`.
        while len(readHeap) and (readHeap[0][0] < scur.reference_id or readHeap[0][1] <= scur.reference_start):
            heapq.heappop(readHeap)

        # Add SV windows from scur to `rsvwHeap`
        rsvwGen = findSvWindowsInRead(
            scur, reffa, wSizeMax, svLen, gapdistance, margin)
        try:
            heapq.heappush(rsvwHeap, (next(rsvwGen), rsvwGen))
        except StopIteration:
            pass
        # Add the read to the `readHeap`
        heapq.heappush(readHeap, (scur.reference_id,
                                  scur.reference_end, scur.reference_start, idx, scur))

    # Flush any remaining SV windows.
    while len(rsvwHeap):
        rsvw, rsvwGen = heapq.heappop(rsvwHeap)
        # Find the reads that cover the window.
        coveringReads = set()
        for dummy_chrom, chromEnd, chromStart, dummy_idx, read in readHeap:
            if chromEnd >= rsvw.refEnd + margin and chromStart <= rsvw.refStart - margin:
                coveringReads.add(read)
        rsvw.coveringReads = coveringReads
        try:
            # add the next read SV window from the generator
            heapq.heappush(rsvwHeap, (next(rsvwGen), rsvwGen))
        except StopIteration:
            pass
        yield rsvw


def callStructuralVariants(bam, reffa, wSizeMax, svLen, lengthWiggle, positionWiggle, basepairIdWiggle,
                           mapq, secondary, duplicate, qcfail, margin, gapdistance, samples):
    """To identify structural variants from BAM alignments:
        1. Find windows in each read that contain an excess of a certain CIGAR operation.
        2. Cluster similar windows from different reads.
        3. Summarize into structural variant calls.

        Return `StructuralVariant` objects ordered by chrom,chromStart.
    """

    activelist = []   # read SV window clusters that might still be extended
    svheap = []       # heap of SV calls
    for rsvw in findSvWindowsInBam(bam, reffa, wSizeMax, svLen, mapq, secondary, duplicate, qcfail, margin, gapdistance):
        rsvwc = ReadSvWindowCluster([rsvw])  # new cluster for the new window

        # Add into the new cluster any existing clusters that overlap.  The new
        # window might merge two or more existing clusters into one.  Call structural
        # variants from the clusters that can not be extended.
        nextactivelist = []
        for svwc in activelist:
            # A cluster can not be extended when its rightmost window starts prior
            # to the current window (allowing for positionWiggle).
            if svwc.maxRefStart[0] < rsvw.refName or svwc.maxRefStart[1] + positionWiggle < rsvw.refStart:
                # Call structural variants from the complete window.
                for sv in svwc.toStructuralVariants(StructuralVariant, samples):
                    heapq.heappush(svheap, sv)
            elif rsvwc.overlaps(svwc, lengthWiggle, positionWiggle, basepairIdWiggle):
                rsvwc.merge(svwc)  # merge into the new cluster
            else:
                nextactivelist.append(svwc)
        nextactivelist.append(rsvwc)
        activelist = nextactivelist

        # minimum start position of any active cluster
        minRefStart = min([svwc.minRefStart for svwc in activelist])
        # Flush the structural variants for which it is certain that no active or future
        # cluster will produce a structural variant that starts earlier.
        while len(svheap) and (svheap[0].chrom, svheap[0].chromStart) < minRefStart:
            yield heapq.heappop(svheap)

    # No cluster can be further extended.
    for svwc in activelist:
        for sv in svwc.toStructuralVariants(StructuralVariant, samples):
            heapq.heappush(svheap, sv)
    # Flush any remaining structural variants.
    while len(svheap):
        yield heapq.heappop(svheap)


def svcall(bamin, reffa, bedout, cfg, ref_regions=None):
    """
    Call structural variants from sorted chain alignments bam file, outputs to BED.
    Taking cfg as parameter input.
    Also writes `.vcf`, at same path/basename as BED.
    """
    reffa = get_fa_from_referenceset_or_fa(reffa)
    return _svcall(bamin=bamin, reffa=reffa, bedout=bedout,
                   wsizemax=cfg.wsizemax, svlength=cfg.svlength,
                   min_readcount=cfg.min_readcount, min_readpercentage=cfg.min_readpercentage,
                   mapq=cfg.call_min_mapq, secondary=cfg.secondary, duplicate=cfg.duplicate,
                   qcfail=cfg.qcfail, margin=cfg.margin, gapdistance=cfg.gapdistance,
                   ref_regions=ref_regions,
                   K=cfg.downsample_max_readcount, W=cfg.downsample_windowlength,
                   downsample_randomseed=cfg.downsample_randomseed)


def _svcall(bamin, reffa, bedout, wsizemax, svlength, min_readcount, min_readpercentage,
            mapq, secondary, duplicate, qcfail, margin, gapdistance, ref_regions, K,
            W, downsample_randomseed):
    """
    Call structural variants from sorted chain alignments bam file, outputs to BED.
    Parameters:
        bamin --- input sorted chain alignments in bam file
        reffa --- reference fasta, e.g., human reference
        bedout --- output BED|Vcf file
        wsizemax --- max window size
        svlength --- search all optimal windows with a maximum size of `wsizemax` that have an
                     excess of at least `svlength`.
        min_readcount --- minimum num of supportive reads to call sv
        min_readpercentage --- minimum percentage of supportive reads over coverage to call sv

        K --- number of reads per sample in each window must not exceed K
        W --- reference window size
    """
    if not is_bed(bedout) and not is_vcf(bedout):
        raise ValueError("%s must be either bed or vcf." %bedout)
    log.info("_svcall(%r, %r, %r, %r)", bamin, reffa, bedout, ref_regions)

    o_bed_fn, o_vcf_fn = bedout[:-4] + '.bed', bedout[:-4] + '.vcf'

    def is_good_aln(aln): # return True if aln should be kept, False otherwise
        return is_good_mapped_alignment(aln, allow_secondary=secondary, min_mapq=mapq, allow_qcfail=qcfail, allow_duplicate=duplicate) or \
               is_inv_aln(aln)

    def aln_to_window(aln):
        """Given an alignment, return its window id.
        (reference_id, window_index_of_alignment_start_position_in_reference_given_window_size_W)
        W -- num bases in each window
        """
        return (aln.reference_id,  aln.reference_start // W)

    def yield_aln(yield_obj_f, K, allowed_keys):
        """yield good alignedseg while cap coverage per sample (e.g., mother/father/proband) per window (size=W) by K.
        """
        return yield_sampled_aln(yield_obj_f=yield_obj_f, is_good_obj_f=is_good_aln,
                obj_to_group_f=aln_to_window, obj_to_key_f=get_sample_from_alignedseg,
                K=K, allowed_keys=allowed_keys, downsample_randomly=True,
                downsample_randomseed=downsample_randomseed)

    # Open input and output files.
    with AnnotateSampleBamStream(fn=bamin, ref_regions=ref_regions, require_sorted=True) as reader:
        samples = sorted(get_samples_from_header(reader.header) if not is_json(bamin) \
                else json_to_fns_and_samples(bamin)[1])
        log.info("Biosamples are  %r", samples)

        aln_yielder = yield_aln(yield_obj_f=reader, K=K, allowed_keys=samples)

        with Fastafile(reffa) as reffa, BedWriter(o_bed_fn, samples=samples) as bed_writer, \
            VcfWriter(o_vcf_fn, samples=samples) as vcf_writer:
            sv_idx = 0
            for sv in callStructuralVariants(aln_yielder, reffa, wsizemax, svlength,
                                             C.LENGTHWIGGLE.val, C.POSITIONWIGGLE.val, C.BASEPAIRIDWIGGLE.val,
                                             mapq, secondary, duplicate, qcfail, margin, gapdistance, samples):
                if sv.pass_filter_criteria(min_readcount=min_readcount,
                                           min_readpercentage=min_readpercentage):
                    sv_idx += 1
                    bed_writer.writeRecord(sv.to_bed().set_pbsv_id(sv_idx))
                    vcf_writer.writeRecord(sv.to_vcf(reffa).set_pbsv_id(sv_idx))
