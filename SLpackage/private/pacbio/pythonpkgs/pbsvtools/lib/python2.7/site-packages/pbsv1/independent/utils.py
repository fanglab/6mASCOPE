"""Define util functions commonly used"""
from __future__ import absolute_import
from __future__ import division

import re
import os
import os.path as op
import logging
import collections
import string
import random
import sys
import heapq

try:
    from pipes import quote
except Exception: # pragma: no cover
    from shlex import quote # pylint: disable=no-name-in-module

from ..__utils import backticks

# List of important public functions.
#__all__ = ['autofmt', 'realpath', 'mv_cmd', 'rmpath', 'execute', 'execute_as_bash', 'is_sam', 'is_bam',
#'is_referenceset_xml', 'is_fofn', 'is_json', 'is_xml', 'is_bed', 'is_vcf', 'is_fasta', 'is_fasta_gz',
#'str2bool', 'read_mode_of_file', 'bai_of_bam', 'merge_sam_header', 'count_kmers', 'revcomp',
#'is_tandem_repeat', 'items_to_str']

log = logging.getLogger()

# Regular expression pattern of sample strings: must be a string
# of length >= 1, the leading character must be a letter or number,
# the remaining characters must be in [a-zA-Z0-9\_\-]
SAMPLE_CHARSET_RE_STR = '[a-zA-Z0-9\-\_]'
SAMPLE_CHARSET_RE = re.compile(r"{}".format(SAMPLE_CHARSET_RE_STR))
SAMPLE_RE = re.compile(r"^{}".format(SAMPLE_CHARSET_RE_STR)+"{1,}$")


def autofmt(filename, validfmts, defaultfmt=None):
    """Infer the format of a file from its filename.  As a convention all the
    format to be forced with prefix followed by a colon (e.g. "fmt:filename").

    `validfmts` is a list of acceptable file formats
    `defaultfmt` is the format to use if the extension is not on the valid list

    returns `filename`,`fmt`
    """
    colonix = filename.find(":")
    if colonix != -1:
        extension = filename[:colonix]
        filename = filename[(colonix+1):]
    else:
        extension = None
        for validfmt in validfmts:
            if filename.endswith(validfmt):
                extension = filename[-len(validfmt):]
    return filename, (extension.lower() if extension in validfmts else defaultfmt)


def _is_fmt(fn, validfmts):
    return autofmt(fn, validfmts)[1] in validfmts

def is_sam(fn):
    """Return true if a file extension is sam"""
    return _is_fmt(fn, ["sam"])

def is_bam(fn):
    """Return true if a file extension is bam"""
    return _is_fmt(fn, ["bam"])

def is_fofn(fn):
    """Return true if a file extension is fofn"""
    return _is_fmt(fn, ["fofn"])

def is_json(fn):
    """Return true if a file extension is json"""
    return _is_fmt(fn, ["json"])

def is_bed(fn):
    """Return true if a file extension is bed"""
    return _is_fmt(fn, ["bed"])

def is_interval(fn):
    """Return true if a file extension is interval"""
    return _is_fmt(fn, ["interval"])

def is_vcf(fn):
    """Return true if a file extension is vcf"""
    return _is_fmt(fn, ["vcf"])

def is_referenceset_xml(fn):
    """Return true if a file extension is referenceset.xml"""
    return _is_fmt(fn, ["referenceset.xml"])

def is_alignmentset(fn):
    """Return true if a file extension is alignmentset.xml"""
    return _is_fmt(fn, ["alignmentset.xml"])

def is_subreadset(fn):
    """Return true if a file extension is subreadset.xml"""
    return _is_fmt(fn, ["subreadset.xml"])


def is_xml(fn):
    """Return true if a file extension is xml"""
    return _is_fmt(fn, ["xml"])


def is_fasta(fn):
    """Return true if a file extension is fa or fasta"""
    return _is_fmt(fn, ["fa", "fasta"])


def is_fasta_gz(fn):
    """Return true if a file extension is .fasta.gz"""
    return fn.endswith(".fasta.gz")

def is_stdin(fn):
    """Return true if file is stdin"""
    return fn in ['-', 'stdin']


def read_mode_of_file(fn):
    """Return read mode of file. 'r' for sam, 'rb' for bam."""
    fn, fmt = autofmt(fn, ['sam', 'bam'], defaultfmt=None)
    if not fmt:
        raise ValueError("Could not get read mode of file %r." % fn)
    return 'r' if fmt == 'sam' else 'rb'


def str2bool(s):
    """Convert a string to bool.
    Return False if s is 'F', 'False', '0', '', 'no', 'n'; otherwise, return True
    """
    return not s.lower() in ['f', 'false', '0', '', 'no', 'n']


def bai_of_bam(fn):
    """Return bai file of a bam"""
    return fn + ".bai"

def transpaths_of_bam(fn):
    return fn + '.transpaths'


def has_bai_of_bam(fn):
    return op.exists(bai_of_bam(fn))


def update_sam_header(current, extra):
    assert extra, 'There must be fields to merge into the current header.'
    assert isinstance(current, dict)
    assert isinstance(extra, dict)
    if not current:
        current.update(extra) # just a copy
        return

    # assuming both sam headers have SQ and RG
    assert 'RG' in current and 'RG' in extra and 'SQ' in current and 'SQ' in extra
    # not doing: merging HD because it is not defined wrt mixed datasets
    # not doing: merging PG
    # merge RG
    for rg in reversed(extra['RG']):
        if rg['ID'] not in [_rg['ID'] for _rg in current['RG']]:
            current['RG'].append(rg)
    # merge SQ
    for sq in reversed(extra['SQ']):
        if sq['SN'] not in [_sq['SN'] for _sq in current['SQ']]:
            current['SQ'].append(sq)

def merge_sam_header(lhs, rhs):
    """Merge lhs sam header with rhs sam header and return dict.
    lhs --- left hand side sam header dict
    rhs --- right hand side sam header dict
    """
    assert lhs or rhs
    current = {}
    if lhs:
        update_sam_header(current, lhs)
    if rhs:
        update_sam_header(current, rhs)
    assert current
    return current

def merge_sam_headers(headers):
    """Merge sam headers and return a dict of merged header.
    If input is empty, return {}.
    """
    ret = {}
    for h in headers:
        # Accumulate in ret to avoid extra copies.
        update_sam_header(ret, h)
    return ret


def _fns2fofn(i_fns, o_fofn):
    """Write input fns to output fofn"""
    with open(o_fofn, 'w') as writer:
        writer.write('\n'.join([f.strip() for f in i_fns]))


def _merge_bam_cmd(i_bam_fns, o_bam_fn, nproc=8):
    """Merge bam files in i_bam_fns to o_bam_fn"""
    if len(i_bam_fns) == 0:
        raise ValueError("No input bam files.")
    if len(i_bam_fns) == 1:
        cmd = 'cp %s %s' % (i_bam_fns[0], o_bam_fn)
        return cmd

    fofn = os.path.join(os.path.dirname(o_bam_fn), 'input_bam.fofn')
    _fns2fofn(i_fns=i_bam_fns, o_fofn=fofn)
    return 'samtools merge -1 -c -b %s %s -f --threads %s' % (fofn, o_bam_fn, int(nproc))
    # TODO: Fix race-condition on input_bam.fofn
    # TODO: Clean up input_bam.fofn, maybe.


def _sort_bam_cmd(i_bam_fn, o_bam_fn, nproc=8, tmp_dir=None):
    """Sort i_bam_fn to o_bam_fn"""
    cmd = 'samtools sort %s -o %s --threads %s' % (i_bam_fn, o_bam_fn, int(nproc))
    return cmd + ' -T {}'.format(tmp_dir) if tmp_dir else cmd


def _index_bam_cmd(i_bam_fn, nproc=1):
    """Index *.bam and create *.bam.bai"""
    return 'samtools index %s -@ %s' % (i_bam_fn, nproc)


def realpath(f):
    """Return absolute, user expanded path."""
    return op.abspath(op.expanduser(f))


def mv_cmd(src, dst):
    """cmd to move src file to dst"""
    if realpath(src) != realpath(dst):
        return "mv %s %s" % (src, dst)
    else:
        return ""

def rmpath_cmd(path):
    assert path
    return "if [ -e {path} ]; then chmod +w -R {path} && rm -rf {path}; fi".format(
            path=quote(path))

def rmpath(path):
    """Remove a file or a directory"""
    execute(rmpath_cmd(path))

def execute(cmd, errmsg="", errcls=RuntimeError):
    """Execute command and check exit code. If exit code is not
    0, raise RuntimeError with errmsg.
    """
    log.debug("CMD: " + cmd)
    out, _code, _msg = backticks(cmd)
    if _code != 0:
        msgs = [msg for msg in ["CMD failed: %s" % cmd, _msg, errmsg]
                if len(msg) > 0]
        raise errcls("\n".join(msgs))
    return out


def cmds_to_bash(cmds):
    """Turn a list of cmds into a bash script.
    """
    return """\
#!/bin/bash
set -vexubE -o pipefail
%s
""" % '\n'.join(cmds)


def execute_as_bash(cmds, bash_sh_fn):
    """Write cmds to a *.sh file, and execute this sh file"""
    fn = bash_sh_fn
    content = cmds_to_bash(cmds)
    with open(fn, 'w') as writer:
        writer.write(content)
    log.info("RUN: %r", fn)
    return execute('/bin/bash %s' % fn)


def mktemp_cmd(local_tmp_dir_prefix):
    """mktemp command to create a local temp dir"""
    return "mktemp -d %sXXXXXX" % local_tmp_dir_prefix


def count_kmers(k, seq):
    """Return a map from kmer of size `k` to count in `seq`"""
    result = collections.defaultdict(int)
    for i in range(0, 1+len(seq)-k):
        result[seq[i:i+k]] += 1
    return result


def kmertopos(k, seq):
    """Return a map from kmer of size `k` to positions in `seq` where the kmers occur"""
    result = collections.defaultdict(list)
    for i in range(0, 1+len(seq)-k):
        result[seq[i:i+k]].append(i)
    return result


def find_best_kmer_diagonal(kmertoposA, kmertoposB, bandwidth, ignore_self_diagonal=False):
    """To approximate the best alignment between sequences A and B, find the
    highest number of basepairs in sequence A involved in kmer matches within a single
    diagonal band in an A-to-B alignment.  The size of the diagonal band is
    defined as +/- `bandwidth`.  So, bands are `1+2*bandwidth` basepairs wide.
    """
    # Map from diagonal number to positions in A that start a kmer match.
    diagonaltoposA = collections.defaultdict(set)
    for kmer in kmertoposA:
        for posA in kmertoposA[kmer]:
            for posB in kmertoposB[kmer]:
                diagonal = posA - posB
                if diagonal == 0 and ignore_self_diagonal:
                    continue

                # contribute the match to all diagonals that are +/- bandwidth
                for d in range(diagonal-bandwidth, diagonal+bandwidth+1):
                    diagonaltoposA[d].add(posA)

    # Find the number of A basepairs in kmers matches in each diagonal band.
    assert len(kmertoposA) > 0
    k = len(kmertoposA.keys()[0]) # kmer size
    bestscore = 0 # best score yet
    for diagonal in diagonaltoposA:
        score = 0 # number of A basepairs in kmer matches in this diagonal band
        b,e = 0,0 # begin,end of current run of basepairs in kmer match
        for posA in sorted(diagonaltoposA[diagonal]):
            if posA > e: # no overlap with previous run
                score += (e - b)
                b = posA
            e = posA + k
        score += (e - b)
        if score > bestscore:
            bestscore = score

    return bestscore


# Support all arbitrary nucleotide characters described in
# https://droog.gs.washington.edu/parc/images/iupac.html
RCNUC = {"A":"T", "C":"G", "G":"C", "T":"A", "N":"N",
         "U":"A", "M":"K", "R":"Y", "W":"W", "S":"S",
         "Y":"R", "K":"M", "V":"B", "H":"D", "D":"H",
         "D":"H", "B":"V",
         "a":"t", "c":"g", "g":"c", "t":"a", "n":"n",
         "u":"a", "m":"k", "r":"y", "w":"w", "s":"s",
         "y":"r", "k":"m", "v":"b", "h":"d", "d":"h",
         "d":"h", "b":"v"}

def revcomp(seq):
    """Reverse complement a sequence."""
    rcseq = ""
    for b in reversed(seq):
        if b not in RCNUC.keys():
            raise ValueError('%s is not a valid Nucleotide' % b)
        rcseq += RCNUC[b]
    return rcseq


def is_tandem_repeat(seq, min_selfshared_kmer_percentage=0.4):
    """Naive way of testing whether a sequence is a tandem repeat
       (has a strong off-main-diagonal self alignment)."""
    k = 6
    if len(seq) < k:
        return False
    seqkmerpos = kmertopos(k=k, seq=seq.upper())
    best_kmerbp = find_best_kmer_diagonal(seqkmerpos, seqkmerpos, bandwidth=25, ignore_self_diagonal=True)
    return (best_kmerbp/len(seq)) > min_selfshared_kmer_percentage


def match_sample_pattern(s):
    """Return True if string s matches sample pattern.
    ...doctest:
        >>> strs = ['abc', 'a-b', 'A_B', 'a', '-ab', '_abc', 'ab!', '', 'a', ' ab ']
        >>> [match_sample_pattern(s) for s in strs]
        [True, True, True, True, True, True, False, False, True, False]
    """
    return SAMPLE_RE.search(s) is not None


def generate_random_sample_str():
    """Generate a random sample string. Leading character must be either a letter or number,
    the rest must be letter, number, '_' or '-', length = 16 .
    """
    leading_letter = rand_alnum_generator()
    remaining_letters = ''.join(random.choice(string.digits + string.letters + '-_') for _ in range(15))
    return leading_letter + remaining_letters


def assert_items_unique(items, errmsg):
    """Assert items in the items list are all unique, raise an AssertionError if this is violated."""
    sorted_items = sorted(items)
    for idx in range(0, len(sorted_items)-1):
        if sorted_items[idx] == sorted_items[idx+1]:
            raise AssertionError('%s: %s!' % (errmsg, sorted_items[idx]))

def rand_alnum_generator():
    """Generate a random digit or alphabet in [a-zA-Z0-9]."""
    return random.choice(string.digits + string.letters)


def sanitize_sample(sample):
    """Simple method to sanitize sample to match sample pattern
    ...doctest:
        >>> def a_generator(): return 'a'
        >>> sanitize_sample('1' * 20) # no length limit
        '11111111111111111111'
        >>> sanitize_sample('-123')
        '-123'
        >>> sanitize_sample('123 !&?') # all invalid characters go to '_'
        '123____'
    """
    if len(sample) == 0:
        raise ValueError('Sample must not be an empty string')
    sanitized_sample = ''
    for c in sample:
        if not SAMPLE_CHARSET_RE.search(c):
            c = '_'
        sanitized_sample +=  c
    return sanitized_sample


def sanitize_samples(samples):
    """Sanitize samples to match sample pattern,
    Return {sample: sanitized_sample} if sample names are sanitizable,
    otherwise raise ValueError

    1. Keep the first round of sanitation to replace illegal characters with underscores.
    2. In the second round, if duplicate names exist (as a results of sanitizing in round 1),
       crash the job with the error message: "User submitted multiple samples with the same
       Bio Sample Name, after correction of illegal characters. Aborting." This error
       should appear in the master log.
    3. Remove any constraints on sample name length. The SL UI states the character limit.
    """
    sample2sanitized = {sample: sanitize_sample(sample) for sample in samples}
    # If first round of sanitation yield duplicates, crash with error message
    if len(set(sample2sanitized.values())) != len(sample2sanitized):
        errmsg = 'User submitted multiple samples with the same Bio Sample Name, after ' + \
                 'correction of illegal characters: {!r}. Aborting.'.format(sample2sanitized)
        log.error(errmsg)
        raise ValueError(errmsg)
    return sample2sanitized


def items_to_str(items, sep='\t'):
    """Return a sep delimited string of all items.
    ...doctest:
        >>> items_to_str([1,2,3], ',')
        '1,2,3'
    """
    return sep.join([str(item) for item in items])

def readname2moviename(readname):
    """
    ...doctest:
        >>> readname2moviename('movie/0/1_2 blaa')
        'movie'
    """
    return readname.split(' ')[0].split('/')[0]

def readname2zmwname(readname):
    """
    ...doctest:
        >>> readname2zmwname('movie/0/1_2 blaa')
        'movie/0'
    """
    return '/'.join(readname.split(' ')[0].split('/')[0:2])

def zmwname2moviename(zmwname):
    """
    ...doctest:
       >>> zmwname2moviename('movie/0')
       'movie'
    """
    return zmwname.split('/')[0]

def join_dict(d1, d2):
    """Join dict objects, use keys in d1 and d2 to map values of d1 to values of d2.
    ...doctest:
        >>> join_dict({'k1': 'v1', 'k2': 'v2'}, {'k1': 'm1', 'k2':'m2', 'k3': 'm3'})
        {'v1': 'm1', 'v2': 'm2'}
    """
    ret = {}
    for k1, v1 in d1.iteritems():
        if k1 not in d2:
            raise ValueError("Could not find {k1} in {d2}".format(k1=k1, d2=d2))
        elif v1 in ret and ret[v1] != d2[k1]:
            raise ValueError('{v1} can map to different values {dk1}, {dk2}'.format(v1=v1, dk1=ret[v1], dk2=d2[k1]))
        else:
            ret[v1] = d2[k1]
    return ret


def add_readgroups_to_header(header, readgroups):
    """Given a BAM header, and a list read groups, merge read groups to the input BAM header
    and return merged BAM header.
    ...doctest:
        >>> header = {'HD': {'SO': 'coordinate'}, 'SQ': [{'SN':'chr1', 'LN':100}, {'SN':'chr2', 'LN':200}]}
        >>> new_header = add_readgroups_to_header(header, [{'ID': 'rg1', 'SM': 'sample1', 'PU': 'movie1'}])
        >>> rg = new_header['RG'][0]
        >>> rg['ID'], rg['SM'], rg['PU']
        ('rg1', 'sample1', 'movie1')
        >>> new_header['HD'], new_header['SQ'][0], new_header['SQ'][1]
        ({'SO': 'coordinate'}, {'LN': 100, 'SN': 'chr1'}, {'LN': 200, 'SN': 'chr2'})
    """
    if not 'RG' in header:
        header['RG'] = []
    header['RG'].extend(readgroups)
    return header


def heapq_sampling_one_move(i, s_i, K, R):
    """
    This function is one move of a subsampling process.

    The whole process is to put the K largest items to R

    This one move function reads an input object s_i, whose index is i,
    and modifies output heapq contiainer R so that total number of objects in R
    must not exceed K.

    R is a heap queue of items.

    This move looks at s_i, (the i-th element of S), compare s_i with items in R.
    * if R size is smaller than K, heappush s_i to R
    * if R size equals K
      ** if s_i is smaller than or equal to any item in R, throw away s_i
      ** if s_i is greater than the smallest item in R,
         heap pop the smallest item from R and heappush s_i to R.
    """
    if K == 0 or i < K: # heapq bucket not yet full, keep (score_i, s_i)
        heapq.heappush(R, s_i)
    else:
        # R is full, it always stores the largest K items
        if R[0] < s_i:
            heapq.heapreplace(R, s_i)
        # otherwise score_i is smaller than the smallest in heapq, throw away s_i


def cmds2str(cmds, sep=" && "):
    return sep.join([c for c in cmds if len(c) > 0])


def make_fai_cmd(in_fa):
    """return cmd string to make fai"""
    return 'samtools faidx %s' % in_fa


def ln_cmd(src, dst):
    if op.realpath(src) == op.realpath(dst):
        return ""
    else:
        return 'ln -sf %s %s' % (src, dst)


def _link_or_make_fai_cmd(in_fai, out_fa):
    """If in_fai exists, symlink it as fai of out_fa, otherwise make fai for out_fa"""
    assert in_fai.endswith('.fai')
    if op.exists(in_fai): # if in_fai exists, make a link
        log.info("fai index file %s exists, make symbolic links" % (in_fai))
        return ln_cmd(src=in_fai, dst=(out_fa + '.fai'))
    else: # not exist, call `samtools index` to make fai.
        log.info("Generate fai index for file %s" % (out_fa))
        return make_fai_cmd(out_fa)

def _fai(in_fa):
    """Infer fai file paths from in_fa"""
    return '%s%s' % (in_fa, '.fai')
