"""
Define classes to represent SAM records and read SAM records.
"""
from collections import namedtuple
import logging

from isocollapse.independent.utils import is_sam, is_bam, is_transcriptalignmentset
from isocollapse.libs import Samfile
from isocollapse.clustertree import ClusterTree  # pylint: disable=no-name-in-module
from pbcore.io import TranscriptAlignmentSet

# __author__ = "etseng@pacificbiosciences.com"


Interval = namedtuple('Interval', ['start', 'end'])


def iter_cigar_string(cigar_string):
    """Iterate over a cigar string, each iter returns a tuple of
    (number, cigar_character) e.g., (10, 'M')"""
    CIGAROPS = 'MIDNSHP=X'
    NUMBERS = '0123456789'
    num = cigar_string[0]
    for s in cigar_string[1:]:
        if s in CIGAROPS:
            yield int(num), s
            num = ''
        else:
            if s in NUMBERS:
                num += s
            else:
                raise ValueError("Unable to parse {} as number in cigar".format(s))


def parse_cigar(cigar, offset):
    """
    Returns (segments, num_ins, num_del, num_mat_or_sub, query_start, query_end)
    where,
        segments is a list of Interval objects, of which start and end are
        genomic segment locations counting offset (e.g., offset = reference_start)
        num_ins, num_deletion: num of insertions, deletions w.r.t. reference
        num_mat_or_sub: num of matches or substitutions
        query_start, query_end: offset of query start and end position w.r.t.
        query read sequence.

    M - match
    I - insertion w.r.t. to ref
    D - deletion w.r.t. to ref
    N - skipped (which means splice junction)
    S - soft clipped
    H - hard clipped (not shown in SEQ)

    ex: 50M43N3D
    """
    segments = []
    query_start = 0
    cur_start = offset
    cur_end = offset
    first_thing = True
    q_aln_len = 0
    num_del = 0
    num_ins = 0
    num_mat_or_sub = 0
    num_equl = 0
    num_diff = 0
    for num, cigar_type in iter_cigar_string(cigar):
        if cigar_type == 'H' or cigar_type == 'S':
            if first_thing:
                query_start += num
        elif cigar_type == 'I':
            q_aln_len += num
            num_ins += num
        elif cigar_type == 'M':
            cur_end += num
            q_aln_len += num
            num_mat_or_sub += num
        elif cigar_type == 'D':
            cur_end += num
            num_del += num
        elif cigar_type == '=':
            cur_end += num
            q_aln_len += num
            num_mat_or_sub += num
            num_equl += num
        elif cigar_type == 'X':
            cur_end += num
            q_aln_len += num
            num_mat_or_sub += num
            num_diff += num
        elif cigar_type == 'N':  # junction, make a new segment
            segments.append(Interval(cur_start, cur_end))
            cur_start = cur_end + num
            cur_end = cur_start
        first_thing = False
    if cur_start != cur_end:
        segments.append(Interval(cur_start, cur_end))
    query_end = query_start + q_aln_len
    return segments, num_ins, num_del, num_mat_or_sub, query_start, query_end, num_equl, num_diff


class SAMRecordBase(object):
    """
    Base class for a SAMRecord.
    """

    def __init__(self):
        self.qID = None
        self.sID = None

        self.qStart = None
        self.qEnd = None

        self.sStart = None
        self.sEnd = None

        self.sLen = None
        self.qLen = None

        self.cigar = None
        self.strand = None

        self.segments = None

        self.num_nonmatches = None
        self.num_ins = None
        self.num_del = None
        self.num_mat_or_sub = None

        self.qCoverage = None
        self.sCoverage = None
        self.identity = None

    def __str__(self):
        msg =\
            """
        qID: {q}
        sID: {s}
        cigar: {c}
        sStart-sEnd: {ss}-{se}
        qStart-qEnd: {qs}-{qe}
        segments: {seg}
        strand: {f}

        coverage (of query): {qcov}
        coverage (of target): {scov}
        alignment identity: {iden}
        """.format(q=self.qID, s=self.sID, seg=self.segments, c=self.cigar, f=self.strand,
                   ss=self.sStart, se=self.sEnd, qs=self.qStart, qe=self.qEnd,
                   iden=self.identity, qcov=self.qCoverage, scov=self.sCoverage)
        return msg

    def __eq__(self, other):
        def _cmp_(lhs, rhs):
            if lhs is None and rhs is None:
                return True
            else:
                return abs(lhs - rhs) <= 1e-6
        return (self.qID == other.qID and self.sID == other.sID and
                self.qStart == other.qStart and self.qEnd == self.qEnd and
                self.sStart == other.sStart and self.sEnd == other.sEnd and
                self.qLen == other.qLen and self.sLen == other.sLen and
                self.cigar == other.cigar and self.strand == other.strand and
                self.segments == other.segments and
                _cmp_(self.identity, other.identity) and
                _cmp_(self.qCoverage, other.qCoverage) and
                _cmp_(self.sCoverage, other.sCoverage))


class MM2Record(SAMRecordBase):
    """Class represents GAMP SAM Record or PBMM2 SAM Record."""

    def __init__(self, alnseg, ref_len_dict=None, query_len_dict=None):
        """
        pbmm2 alignments have following optional fields:
            ib: barcode summary, ignore
            im: supportive zmws of this transcript
            is: number of supportive zmws
            iz: maximum number of zmws used for polishing
            rq: predicted accuracy for polished isoform
            zm: transcript ID, not ZMW
        , which are not used in this class.

        0. qID
        1. strand
        2. sID
        3. 1-based offset sStart
        4. mapping quality (ignore)
        5. cigar
        6. name of ref of mate alignment (ignore)
        7. 1-based offset sStart of mate (ignore)
        8. inferred fragment length (ignore)
        9. sequence (ignore)
        10. read qual (ignore)
        11. optional fields
        """
        super(MM2Record, self).__init__()
        self.peer = alnseg

        self.qID = alnseg.query_name
        if alnseg.reference_id == -1:  # means no match! STOP here
            self.sID = None
            return
        else:
            self.sID = alnseg.reference_name

        self.strand = '-' if alnseg.is_reverse else '+'
        self._strand = self.strand  # serve as backup for debugging
        self.cigar = alnseg.cigarstring

        self.sStart = alnseg.reference_start
        (self.segments,
         self.num_ins, self.num_del, self.num_mat_or_sub,
         self.qStart, self.qEnd,
         self._num_equl, self._num_diff) = parse_cigar(cigar=self.cigar, offset=self.sStart)

        self.sEnd = self.segments[-1].end

        if ref_len_dict is not None:
            self.sCoverage = (self.sEnd - self.sStart) * 1. / ref_len_dict[self.sID]
            self.sLen = ref_len_dict[self.sID]

        if self.strand == '-' and self.qLen is not None:
            self.qStart, self.qEnd = self.qLen - self.qEnd, self.qLen - self.qStart

        if self.qLen is not None:
            self.qCoverage = (self.qEnd - self.qStart) * 1. / self.qLen

        if query_len_dict is not None:  # over write qLen and qCoverage, should be done LAST
            try:
                self.qLen = query_len_dict[self.qID]
            except KeyError: # handle biosample prefix
                # e.g., self.qID == 'mysample_HQ_transcript/4', query_len_dict has 'transcript/4'
                if 'transcript/' in self.qID:
                    qid = self.qID[self.qID.rfind('transcript/'):]
                    self.qLen = query_len_dict[qid]
                else:
                    raise ValueError("Could not find read {} in query length dict {!r}"
                                     .format(self.qID, query_len_dict))
            self.qCoverage = (self.qEnd - self.qStart) * 1. / self.qLen

        self.num_nonmatches = self.num_ins + self.num_del + self._num_diff
        self.identity = 1. - (self.num_nonmatches * 1. /
                              (self.num_del + self.num_ins + self.num_mat_or_sub))

    @property
    def is_mapped(self):
        """Returns True if this SAM record is mapped (i.e., sID is neither None nor *)."""
        return self.sID is not None and self.sID != "*"

    def __repr__(self):
        fs = [self.qID, self.strand, self.sID, self.qStart, self.qEnd, self.sStart, self.sEnd]
        return '(MM2Record: {})'.format(', '.join([str(x) for x in fs]))


def get_alnseg_iterator(filename):
    """Return iterator of pysam AlignedSegment objects"""
    readmode = 'r' if is_sam(filename) else 'rb'
    if is_sam(filename) or is_bam(filename):
        with Samfile(filename, readmode, check_sq=False) as reader:
            for alnseg in reader:
                yield alnseg
    elif is_transcriptalignmentset(filename):
        with TranscriptAlignmentSet(filename) as reader:
            for read in reader:
                yield read.peer
    else:
        raise ValueError("Could not read {!r}".format(filename))


class MM2Reader(object):
    """Class to read pbmm2 TranscriptAlignmentSet file.
    e.x.,
    with MM2Reader("pbmm2.transcriptalignmentset.xml") as reader:
        for sam_record in reader:
            print sam_record
    """

    def __init__(self, filename, ref_len_dict=None, query_len_dict=None):
        self.filename = filename
        self.alnseg_iterator = get_alnseg_iterator(filename)

        self.ref_len_dict = ref_len_dict
        self.query_len_dict = query_len_dict

    def __iter__(self):
        return self

    def __str__(self):
        return "%s reading <%s>" % (self.__class__.__name__, self.filename)

    def next(self):
        """Return the next SAMRecord or stop."""
        return MM2Record(alnseg=next(self.alnseg_iterator),
                         ref_len_dict=self.ref_len_dict,
                         query_len_dict=self.query_len_dict)

    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_value, traceback):
        return self


def iter_transcript_alignments(aln_filename, query_len_dict,
                               min_aln_coverage, min_aln_identity, ignored_ids_writer):
    """
    Iterates over a SORTED TranscriptAlignmentSet file, yields a collection of
    MM2Records that overlap by at least 1 base in the format:
    {'+': list of MM2Records,
     '-': list of MM2Records}

    Parameters:
      query_len_dict -- {query_read: query_read_len}, used for computing qCoverage
      ignored_ids_writer -- file handler writing ignored SAM record.
      min_aln_coverage -- ignore records of which qCoverage < min_aln_coverage
      min_aln_identity -- ignore records of which identity < min_aln_identity
    """

    def sep_by_clustertree(records):
        tree = ClusterTree(0, 0)
        for i, r in enumerate(records):
            tree.insert(r.sStart, r.sEnd, i)
        result = []
        for s, e, indices in tree.getregions():
            result.append([records[i] for i in indices])
        return result

    def sep_by_strand(records):
        """
        Returns {'+': list of + strand SAM records,
                 '-': list of - strand SAM record}
        """
        output = {'+': [], '-': []}
        for r in records:
            output[r.strand].append(r)
        # process + strand using ClusterTree
        output['+'] = sep_by_clustertree(output['+'])
        output['-'] = sep_by_clustertree(output['-'])
        return output

    def write_ignored_ids(msg):
        """Write ignored ids to ignored_ids_writer unless writer is None."""
        if ignored_ids_writer is not None:
            ignored_ids_writer.write(msg)

    records = None  # holds the current set of records that overlap in coordinates

    with MM2Reader(aln_filename, query_len_dict=query_len_dict) as reader:
        first_record = None
        for r in reader:
            if not r.is_mapped:
                write_ignored_ids("{0}\tUnmapped.\n".format(r.qID))
                # ignored_ids_writer.write("{0}\tUnmapped.\n".format(r.qID))
            elif r.qCoverage < min_aln_coverage:
                #ignored_ids_writer.write("{0}\tCoverage {1:.3f} too low.\n".format(r.qID, r.qCoverage))
                write_ignored_ids("{0}\tCoverage {1:.3f} too low.\n".format(r.qID, r.qCoverage))
            elif r.identity < min_aln_identity:
                #ignored_ids_writer.write("{0}\tIdentity {1:.3f} too low.\n".format(r.qID, r.identity))
                write_ignored_ids("{0}\tIdentity {1:.3f} too low.\n".format(r.qID, r.identity))
            else:
                first_record = r
                break
        if first_record is not None:
            records = [first_record]
        else:
            logging.warn("No valid records from %s!", aln_filename)
            return

        # The very first valid SAM record has been added to records,
        # continue to append remaining records and yield
        for r in reader:
            if r.sID == records[0].sID and r.sStart < records[-1].sStart:
                raise ValueError("SAM file %s is NOT sorted. ABORT!" % aln_filename)
            if r.qCoverage < min_aln_coverage:
                #ignored_ids_writer.write("{0}\tCoverage {1:.3f} too low.\n".format(r.qID, r.qCoverage))
                write_ignored_ids("{0}\tCoverage {1:.3f} too low.\n".format(r.qID, r.qCoverage))
            elif r.identity < min_aln_identity:
                #ignored_ids_writer.write("{0}\tIdentity {1:.3f} too low.\n".format(r.qID, r.identity))
                write_ignored_ids("{0}\tIdentity {1:.3f} too low.\n".format(r.qID, r.identity))
            elif r.sID != records[0].sID or r.sStart > max(x.sEnd for x in records):
                yield sep_by_strand(records)
                records = [r]
            else:
                records.append(r)
        yield sep_by_strand(records)
