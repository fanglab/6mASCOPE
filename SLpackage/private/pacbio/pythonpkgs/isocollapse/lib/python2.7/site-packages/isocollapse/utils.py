import os
import os.path as op
import logging

from pbcore.io import ContigSet, FastaReader, FastqReader, TranscriptSet
from .independent.utils import get_files_from_fofn, nfs_exists, is_fasta, assert_fasta, _replace_prefix_in_file_cmd
from .independent.system import execute, mv
from .libs import AlignmentFile
from .io import GroupReader
from pbcommand.models.report import Report, Table, Attribute


log = logging.getLogger(__name__)


def as_contigset(fasta_file, xml_file):
    if fasta_file == xml_file or xml_file is None:
        if not op.isfile(fasta_file) or op.getsize(fasta_file) == 0:
            return ContigSet()
        return ContigSet(fasta_file)
    file_size = op.getsize(fasta_file)

    fai_file = fasta_file + ".fai"
    if op.exists(fai_file):
        os.remove(fai_file)

    ds = ContigSet(fasta_file, generateIndices=True)
    ds.write(xml_file)
    if not file_size > 0:
        with open(fai_file, "w") as fai:
            fai.write("")
    return ds


def add_prefix_to_fasta_readnames(fa_fn, prefix):
    """ Add prefix to read names in fasta file"""
    assert_fasta(fa_fn)
    execute(_replace_prefix_in_file_cmd(fn=fa_fn, prefix='>', new_prefix='>'+prefix))


def add_prefix_to_fastq_readnames(i_fq_fn, prefix):
    """Add prefix to fastq read names."""
    from pbcore.io import FastqReader, FastqWriter
    tmp_o_fq_fn = i_fq_fn + '.tmp.fastq'
    with FastqReader(i_fq_fn) as reader, FastqWriter(tmp_o_fq_fn) as writer:
        for r in reader:
            newname = '{p}{s}'.format(p=prefix, s=r.name)
            writer.writeRecord(newname, r.sequence, r.quality)
    mv(tmp_o_fq_fn, i_fq_fn)


def get_transcript_to_reads_dict_from_transcriptset(i_bam):
    """
    Return {transcript: [reads]} transcripts and associated reads (zmws) from tango output.
    """
    ret = {}
    IM_TAG = 'im'
    IM_SEP = ','
    for r in TranscriptSet(i_bam):
        assert r.peer.has_tag(IM_TAG), \
            '{} must be polished TranscriptSet with {} tag.'.format(i_bam, IM_TAG)
        ret[r.zmwName] = r.peer.get_tag(IM_TAG).split(IM_SEP)
    return dict(ret)


def get_read_length_dict_from_bam(i_bam):
    """Return {read: read_length} from input bam"""
    return {r.query_name: r.query_length for r in AlignmentFile(i_bam, check_sq=False)}


def make_report_json(isoforms_filename, group_filename, out_report_json):
    """
    Make a report json for pbreport
    """
    _cls = FastaReader if is_fasta(isoforms_filename) else FastqReader
    number_isoforms = len([r for r in _cls(isoforms_filename)])
    group_ids = [int(r.name.split('.')[1]) for r in GroupReader(group_filename)]
    number_groups = max(group_ids) if group_ids else 0

    class Constants(object):
        A_N_I_ID = "number_mapped_unique_isoforms"
        A_N_I_DESC = "Number of mapped unique isoforms"

        A_N_L_ID = "number_of_mapped_unique_loci"
        A_N_L_DES = "Number of mapped unique loci"

    attributes = [
        Attribute(Constants.A_N_I_ID, value=number_isoforms, name=Constants.A_N_I_DESC),
        Attribute(Constants.A_N_L_ID, value=number_groups, name=Constants.A_N_L_DES),
    ]
    report = Report(
        id_="isoseq3",
        title="Transcript Mapping",
        attributes=attributes)
    report.write_json(out_report_json)
